{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from agent import Agent, Config\n",
    "from helper import get_paths, extract_query, get_schema_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[STEP 0] Starting 'run' method.\n",
      "User Query:\n",
      "For the day with the lowest ratio of 5y tsy yield to 10y tsy yield \n",
      "    among days where USD to GBP was greater than 0.75, calculate the percentage difference \n",
      "    between the EUR equivalent of the close price and the JPY equivalent of the open price \n",
      "    in the ohlc table.\n",
      "==================================================\n",
      "[STEP 1] Generating SQL JSON from user query...\n",
      "==================================================\n",
      "LLM Response (raw):\n",
      "```json\n",
      "{\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"name\": \"treasury_yields\",\n",
      "      \"alias\": \"tsy\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"tsy_date\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"yield_5_year\",\n",
      "          \"alias\": \"tsy_yield_5_year\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"yield_10_year\",\n",
      "          \"alias\": \"tsy_yield_10_year\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"fxrates\",\n",
      "      \"alias\": \"fx\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"fx_date\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_gbp\",\n",
      "          \"alias\": \"fx_usd_to_gbp\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_eur\",\n",
      "          \"alias\": \"fx_usd_to_eur\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_jpy\",\n",
      "          \"alias\": \"fx_usd_to_jpy\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"ohlc\",\n",
      "      \"alias\": \"ohlc\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"ohlc_date\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"close\",\n",
      "          \"alias\": \"ohlc_close\"\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"open\",\n",
      "          \"alias\": \"ohlc_open\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"joins\": [\n",
      "    {\n",
      "      \"left_table_alias\": \"fx\",\n",
      "      \"right_table_alias\": \"tsy\",\n",
      "      \"left_column\": \"date\",\n",
      "      \"right_column\": \"date\",\n",
      "      \"join_type\": \"inner\",\n",
      "      \"keep_left\": true,\n",
      "      \"keep_right\": true\n",
      "    },\n",
      "    {\n",
      "      \"left_table_alias\": \"fx\",\n",
      "      \"right_table_alias\": \"ohlc\",\n",
      "      \"left_column\": \"date\",\n",
      "      \"right_column\": \"date\",\n",
      "      \"join_type\": \"inner\",\n",
      "      \"keep_left\": false,\n",
      "      \"keep_right\": true\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "==================================================\n",
      "[STEP 2] Compiling and running SQL...\n",
      "==================================================\n",
      "Generated SQL Query:\n",
      "SELECT\n",
      "            \"tsy\".\"date\" AS \"tsy_date\",\n",
      "    \"tsy\".\"yield_5_year\" AS \"tsy_yield_5_year\",\n",
      "    \"tsy\".\"yield_10_year\" AS \"tsy_yield_10_year\",\n",
      "    \"fx\".\"date\" AS \"fx_date\",\n",
      "    \"fx\".\"usd_to_gbp\" AS \"fx_usd_to_gbp\",\n",
      "    \"fx\".\"usd_to_eur\" AS \"fx_usd_to_eur\",\n",
      "    \"fx\".\"usd_to_jpy\" AS \"fx_usd_to_jpy\",\n",
      "    \"ohlc\".\"date\" AS \"ohlc_date\",\n",
      "    \"ohlc\".\"close\" AS \"ohlc_close\",\n",
      "    \"ohlc\".\"open\" AS \"ohlc_open\"\n",
      "        FROM \"fxrates\" \"fx\"\n",
      "INNER JOIN \"treasury_yields\" \"tsy\" ON \"fx\".\"date\" = \"tsy\".\"date\"\n",
      "INNER JOIN \"ohlc\" \"ohlc\" ON \"fx\".\"date\" = \"ohlc\".\"date\"\n",
      "==================================================\n",
      "[STEP 2] SQL Query executed. Here's df.head():\n",
      "              tsy_date  tsy_yield_5_year  tsy_yield_10_year              fx_date  fx_usd_to_gbp  fx_usd_to_eur  fx_usd_to_jpy            ohlc_date  ohlc_close   ohlc_open\n",
      "0  2020-01-01 00:00:00          1.545694           2.420872  2020-01-01 00:00:00       0.744213       0.955216     178.670871  2020-01-01 00:00:00   92.244252   97.847047\n",
      "1  2020-01-02 00:00:00          2.245038           2.566896  2020-01-02 00:00:00       0.778589       0.953731     149.179569  2020-01-02 00:00:00   95.321208   92.102546\n",
      "2  2020-01-03 00:00:00          1.397994           3.327936  2020-01-03 00:00:00       0.885252       0.988302     145.902530  2020-01-03 00:00:00   86.266867  106.361000\n",
      "3  2020-01-06 00:00:00          2.529819           4.022134  2020-01-06 00:00:00       0.776084       0.898221     127.671146  2020-01-06 00:00:00  109.121746   80.813697\n",
      "4  2020-01-07 00:00:00          1.763754           3.628586  2020-01-07 00:00:00       0.760646       0.890543     134.947739  2020-01-07 00:00:00  116.741645  110.707861\n",
      "==================================================\n",
      "[STEP 3] Generating Python prompt...\n",
      "==================================================\n",
      "[STEP 3] Completed: Python prompt generated.\n",
      "Generated Python Prompt:\n",
      "CODE DESCRIPTION:\n",
      "Overall Goal: Identify the day with the lowest ratio of 5-year Treasury yield to 10-year Treasury yield among days where USD to GBP exchange rate was greater than 0.75, and then calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price for that specific day.\n",
      "\n",
      "Step 1: Filter the dataframe (`df`) to include only the rows where the USD to GBP exchange rate (`fx_usd_to_gbp`) is greater than 0.75.\n",
      "\n",
      "Step 2: Create a new column in the filtered dataframe that calculates the ratio of 5-year Treasury yield (`tsy_yield_5_year`) to 10-year Treasury yield (`tsy_yield_10_year`) for each row.\n",
      "\n",
      "Step 3: Identify the row with the minimum ratio value from the new column created in Step 2.\n",
      "\n",
      "Step 4: For the date identified in Step 3, extract the close price in the ohlc table (`ohlc_close`), the open price in the ohlc table (`ohlc_open`), the EUR to USD exchange rate (`fx_usd_to_eur`), and the JPY to USD exchange rate (`fx_usd_to_jpy`).\n",
      "\n",
      "Step 5: Convert the close price from USD to EUR by dividing the close price by the EUR to USD exchange rate.\n",
      "\n",
      "Step 6: Convert the open price from USD to JPY by multiplying the open price by the JPY to USD exchange rate.\n",
      "\n",
      "Step 7: Calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price using the formula: `((EUR_close - JPY_open) / JPY_open) * 100`.\n",
      "\n",
      "Step 8: Output the date identified in Step 3 and the percentage difference calculated in Step 7 as the final result.\n",
      "==================================================\n",
      "[STEP 4] Generating and executing Python code...\n",
      "==================================================\n",
      "Generated Python Code:\n",
      "# Step 1: Filter the dataframe (df) to include only the rows where the USD to GBP exchange rate (fx_usd_to_gbp) is greater than 0.75.\n",
      "filtered_df = df[df['fx_usd_to_gbp'] > 0.75]\n",
      "\n",
      "# Step 2: Create a new column in the filtered dataframe that calculates the ratio of 5-year Treasury yield (tsy_yield_5_year) to 10-year Treasury yield (tsy_yield_10_year) for each row.\n",
      "filtered_df['yield_ratio'] = filtered_df['tsy_yield_5_year'] / filtered_df['tsy_yield_10_year']\n",
      "\n",
      "# Step 3: Identify the row with the minimum ratio value from the new column created in Step 2.\n",
      "min_ratio_row = filtered_df.loc[filtered_df['yield_ratio'].idxmin()]\n",
      "\n",
      "# Step 4: For the date identified in Step 3, extract the close price in the ohlc table (ohlc_close), the open price in the ohlc table (ohlc_open), the EUR to USD exchange rate (fx_usd_to_eur), and the JPY to USD exchange rate (fx_usd_to_jpy).\n",
      "ohlc_close = min_ratio_row['ohlc_close']\n",
      "ohlc_open = min_ratio_row['ohlc_open']\n",
      "fx_usd_to_eur = min_ratio_row['fx_usd_to_eur']\n",
      "fx_usd_to_jpy = min_ratio_row['fx_usd_to_jpy']\n",
      "\n",
      "# Step 5: Convert the close price from USD to EUR by dividing the close price by the EUR to USD exchange rate.\n",
      "eur_close = ohlc_close / fx_usd_to_eur\n",
      "\n",
      "# Step 6: Convert the open price from USD to JPY by multiplying the open price by the JPY to USD exchange rate.\n",
      "jpy_open = ohlc_open * fx_usd_to_jpy\n",
      "\n",
      "# Step 7: Calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price using the formula: ((EUR_close - JPY_open) / JPY_open) * 100.\n",
      "percentage_difference = ((eur_close - jpy_open) / jpy_open) * 100\n",
      "\n",
      "# Step 8: Output the date identified in Step 3 and the percentage difference calculated in Step 7 as the final result.\n",
      "result = {\n",
      "    'date': min_ratio_row['tsy_date'],\n",
      "    'percentage_difference': percentage_difference\n",
      "}\n",
      "result\n",
      "==================================================\n",
      "[STEP 4] Result from executed code:\n",
      "{'date': '2023-08-17 00:00:00', 'percentage_difference': -99.40500314816744}\n",
      "==================================================\n",
      "[STEP 5] Completed run in 38.41 seconds.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Python Execution Failed: the final result must be a float or int, instead got <class 'dict'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 462\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39m# user_query = '''For s in [1,2], of the days where the stock price \u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[39m# movement := close - open was more than s std deviations from the mean, look at the distribution \u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m# of 7yr tsy yield - 5yr tsy yield. To visualize this, assume access to matplotlib.pyplot as plt and \u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[39m# make 2 plots, the left where s = 1 and a histogram of 7yr - 5yr tsy yields with lines at 25 percentile,\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m# 50th percentile, 75th, and then right same with s=2. Then return the median when s=1. \u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39m# '''\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[39mfor\u001b[39;00m user_query \u001b[39min\u001b[39;00m user_queries[:\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 462\u001b[0m     result \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mrun(user_query)  \n\u001b[1;32m    463\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinal numeric result:\u001b[39m\u001b[39m\"\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[15], line 52\u001b[0m, in \u001b[0;36mBasicAgent.run\u001b[0;34m(self, user_query)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39m# Validate final result is float-like\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(result, (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m)):\n\u001b[0;32m---> 52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPython Execution Failed: the final result must be a float or int, instead got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(result)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mfloat\u001b[39m(result)\n",
      "\u001b[0;31mValueError\u001b[0m: Python Execution Failed: the final result must be a float or int, instead got <class 'dict'>"
     ]
    }
   ],
   "source": [
    "class BasicAgent(Agent):\n",
    "\n",
    "    def __init__(self, config: Config, log_data=True, tbls_to_exclude=[]):\n",
    "        super().__init__(config)\n",
    "        self.schema   = get_schema_context(config, tbls_to_exclude)\n",
    "        self.log_data = log_data\n",
    "        self.path_map = get_paths()  \n",
    "\n",
    "    def _log(self, message: str):\n",
    "        \"\"\"\n",
    "        Helper method to handle logging to both console and a log file.\n",
    "        Appends each message as a new line.\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        if self.log_data:\n",
    "            try:\n",
    "                with open(self.path_map['log'], 'a') as f:\n",
    "                    f.write(message + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not write to log file: {e}\")\n",
    "\n",
    "    def run(self, user_query: str) -> float:\n",
    "        \"\"\"\n",
    "        Takes a user query string, runs it through:\n",
    "          get_sql_json -> compile_sql -> get_python_prompt -> execute_python\n",
    "        and returns a float result.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 0] Starting 'run' method.\")\n",
    "        self._log(f\"User Query:\\n{user_query}\")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # 1) Convert the user query to SQL JSON\n",
    "        sql_json = self.get_sql_json(user_query)\n",
    "\n",
    "        # 2) Compile SQL and fetch data into a dataframe\n",
    "        df = self.compile_sql(sql_json)\n",
    "\n",
    "        # 3) Generate a Python prompt describing the next steps\n",
    "        py_prompt = self.get_python_prompt(user_query, df)\n",
    "\n",
    "        # 4) Execute the described Python steps and retrieve the result\n",
    "        result = self.execute_python(py_prompt, df)\n",
    "\n",
    "        end = time.time()\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(f\"[STEP 5] Completed run in {round(end - start, 2)} seconds.\\n\")\n",
    "\n",
    "        # Validate final result is float-like\n",
    "        if not isinstance(result, (int, float)):\n",
    "            raise ValueError(f\"Python Execution Failed: the final result must be a float or int, instead got {type(result)}\")\n",
    "        \n",
    "        return float(result)\n",
    "\n",
    "    def get_sql_json(self, user_query: str) -> dict:\n",
    "        \"\"\"\n",
    "        Takes a user query and asks the LLM to produce a JSON specifying which tables/columns to pull.\n",
    "        Validates the JSON structure and join types.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 1] Generating SQL JSON from user query...\")\n",
    "\n",
    "        schema_context = self.schema\n",
    "        prompt = f'''Given a user query and a SQLite database schema, return ONLY a valid JSON describing the \n",
    "        data required to answer the user query. The JSON should be parsable and adhere to proper JSON syntax.\n",
    "\n",
    "        Instructions:\n",
    "        2. Ensure column names and new column names are strings, and there are no extraneous characters.\n",
    "        3. Be mindful of how many days of data to pull, as certain queries may specify n days but \n",
    "        require more than n to compute the result.\n",
    "        4. Avoid creating new columns or performing calculations; these will be handled in later steps.\n",
    "        5. Ensure new column names are self-explanatory and clear for what they are, not what they will be.\n",
    "        For example do treasury_yield_7_year instead of something like 7y_yield, but don't do\n",
    "        treasury_price_7_year, even if eventually that column will be transformed into price.\n",
    "\n",
    "        Answer ONLY with a JSON in this format:\n",
    "        {{\n",
    "  \"tables\": [\n",
    "    {{\n",
    "      \"name\": \"<db_table_name>\",\n",
    "      \"alias\": \"<alias>\",\n",
    "      \"columns\": [\n",
    "        {{\n",
    "          \"original_name\": \"<col_name_in_db>\",\n",
    "          \"alias\": \"<col_alias_in_output>\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"joins\": [\n",
    "    {{\n",
    "      \"left_table_alias\": \"<alias>\",\n",
    "      \"right_table_alias\": \"<alias>\",\n",
    "      \"left_column\": \"<col_name_in_db>\", \n",
    "      \"right_column\": \"<col_name_in_db>\",\n",
    "      \"join_type\": \"inner\" // or outer, left, right,\n",
    "      \"keep_left\": true // or false to merge then drop left_column,\n",
    "      \"keep_right\": true // or fasle to merge then drop right_coumn\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "        Constraints:\n",
    "        - Join types must be one of: \"inner\", \"left\", \"right\", \"outer\".\n",
    "        - Join keep left/right should only keep absolutely necessary columns- for example\n",
    "        two identical columns shoudn't both be kept\n",
    "        - Join column names must be the OLD name, not the NEW name \n",
    "        - Joins will be applied in order of the json. Note the order does matter here. For example \n",
    "        if the first join is inner(A,B) then next is outer(B, C), what is really happening is \n",
    "        outer(C, inner(A,B)), i.e. not inner(A, outer(B,C))\n",
    "\n",
    "        Database Schema: {schema_context}\n",
    "\n",
    "        Example User Query: Calculate the correlation between 7-year treasury yields and stocks' \n",
    "        close prices over the last 30 days.\n",
    "\n",
    "        Example Labeled Answer:\n",
    "        ```\n",
    "        json\n",
    "        {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"ohlc\",\n",
    "        \"alias\": \"ohlc\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"ohlc_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"close\",\n",
    "            \"alias\": \"stock_close\"\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "        {{\n",
    "        \"name\": \"treasury_yields\",\n",
    "        \"alias\": \"treasury_yields\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"tsy_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_7_year\",\n",
    "            \"alias\": \"tsy_yield_7_year\"\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "    ],\n",
    "    \"joins\": [\n",
    "        {{\n",
    "        \"left_table_alias\": \"ohlc\",\n",
    "        \"right_table_alias\": \"treasury_yields\",\n",
    "        \"left_column\": \"date\",\n",
    "        \"right_column\": \"date\",\n",
    "        \"join_type\": \"inner\",\n",
    "        \"left_keep\": true,\n",
    "        \"right_keep: false\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "    ```\n",
    "        Answer for the following user query: {user_query}\n",
    "        ''' \n",
    "\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for SQL JSON failed: {e}\")\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"LLM Response (raw):\")\n",
    "        self._log(llm_response)\n",
    "\n",
    "        try:\n",
    "            sql_json_str = extract_query(llm_response, type='json')\n",
    "            sql_json = json.loads(sql_json_str)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"SQL JSON Extraction Failed: {e}\")\n",
    "\n",
    "        return sql_json\n",
    "\n",
    "    \n",
    "    def compile_sql(self, sql_json: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transforms the validated JSON (with optional keep flags in the joins) into a SQL SELECT statement,\n",
    "        executes it, and returns the resulting DataFrame.\n",
    "\n",
    "        The JSON structure must have:\n",
    "        {\n",
    "            \"tables\": [\n",
    "                {\n",
    "                    \"name\": \"ohlc\",\n",
    "                    \"alias\": \"ohlc\",\n",
    "                    \"columns\": [\n",
    "                        {\n",
    "                            \"original_name\": \"date\",\n",
    "                            \"alias\": \"ohlc_date\"\n",
    "                        },\n",
    "                        ...\n",
    "                    ]\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"joins\": [\n",
    "                {\n",
    "                    \"left_table_alias\": \"ohlc\",\n",
    "                    \"right_table_alias\": \"treasury_yields\",\n",
    "                    \"left_column\": \"date\",\n",
    "                    \"right_column\": \"date\",\n",
    "                    \"join_type\": \"inner\",\n",
    "                    \"left_keep\": true,\n",
    "                    \"right_keep\": false\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        Returns:\n",
    "            A DataFrame with the queried data.\n",
    "        \"\"\"\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 2] Compiling and running SQL...\")\n",
    "\n",
    "        # 1) Organize the tables in a more flexible structure\n",
    "        #    so we can remove columns if keep flags are false.\n",
    "        table_map = {}  # alias -> { \"name\": <table_name>, \"columns\": [ {original_name, alias}, ... ] }\n",
    "        for tbl in sql_json[\"tables\"]:\n",
    "            table_map[tbl[\"alias\"]] = {\n",
    "                \"name\": tbl[\"name\"],\n",
    "                \"columns\": tbl[\"columns\"][:]  # copy to manipulate\n",
    "            }\n",
    "\n",
    "        # 2) Process each join's keep flags\n",
    "        joins = sql_json.get(\"joins\", [])\n",
    "        for j in joins:\n",
    "            lt_alias = j[\"left_table_alias\"]\n",
    "            rt_alias = j[\"right_table_alias\"]\n",
    "            lt_col   = j[\"left_column\"]\n",
    "            rt_col   = j[\"right_column\"]\n",
    "\n",
    "            # If left_keep = false, remove the left_column from that table's columns\n",
    "            if j.get(\"left_keep\") is False:\n",
    "                # find the column in table_map[lt_alias][\"columns\"] that has original_name == lt_col\n",
    "                filtered_cols = []\n",
    "                for c in table_map[lt_alias][\"columns\"]:\n",
    "                    if c[\"original_name\"] == lt_col:\n",
    "                        # skip it\n",
    "                        continue\n",
    "                    filtered_cols.append(c)\n",
    "                table_map[lt_alias][\"columns\"] = filtered_cols\n",
    "\n",
    "            # If right_keep = false, remove the right_column from that table's columns\n",
    "            if j.get(\"right_keep\") is False:\n",
    "                filtered_cols = []\n",
    "                for c in table_map[rt_alias][\"columns\"]:\n",
    "                    if c[\"original_name\"] == rt_col:\n",
    "                        continue\n",
    "                    filtered_cols.append(c)\n",
    "                table_map[rt_alias][\"columns\"] = filtered_cols\n",
    "\n",
    "        # 3) Build SELECT clause from the (potentially updated) table_map\n",
    "        select_parts = []\n",
    "        for tbl_alias, tbl_info in table_map.items():\n",
    "            for col in tbl_info[\"columns\"]:\n",
    "                original = col[\"original_name\"]\n",
    "                alias = col[\"alias\"]\n",
    "                select_parts.append(f'\"{tbl_alias}\".\"{original}\" AS \"{alias}\"')\n",
    "\n",
    "        if not select_parts:\n",
    "            raise ValueError(\"No columns to select after applying keep flags.\")\n",
    "\n",
    "        select_clause = \",\\n    \".join(select_parts)\n",
    "\n",
    "        # 4) Build FROM + JOIN\n",
    "        #    We still rely on the same join logic, but note we might have removed certain columns.\n",
    "        if len(joins) == 0:\n",
    "            # No joins: just use the first table\n",
    "            all_tables = sql_json[\"tables\"]\n",
    "            if len(all_tables) == 0:\n",
    "                raise ValueError(\"No tables available to compile SQL.\")\n",
    "            first_tbl = all_tables[0]\n",
    "            from_clause = f'\"{first_tbl[\"name\"]}\" \"{first_tbl[\"alias\"]}\"'\n",
    "        else:\n",
    "            # Use the first join's left_table_alias as the base\n",
    "            base_alias = joins[0][\"left_table_alias\"]\n",
    "            base_table_name = table_map[base_alias][\"name\"]\n",
    "            from_clause = f'\"{base_table_name}\" \"{base_alias}\"'\n",
    "\n",
    "            for j in joins:\n",
    "                right_alias = j[\"right_table_alias\"]\n",
    "                right_table_name = table_map[right_alias][\"name\"]\n",
    "                join_type = j[\"join_type\"].upper()\n",
    "                from_clause += (\n",
    "                    f'\\n{join_type} JOIN \"{right_table_name}\" \"{right_alias}\" '\n",
    "                    f'ON \"{j[\"left_table_alias\"]}\".\"{j[\"left_column\"]}\" = '\n",
    "                    f'\"{j[\"right_table_alias\"]}\".\"{j[\"right_column\"]}\"'\n",
    "                )\n",
    "\n",
    "        # 5) Construct final SQL\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            {select_clause}\n",
    "        FROM {from_clause}\n",
    "        \"\"\".strip()\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"Generated SQL Query:\")\n",
    "        self._log(query)\n",
    "\n",
    "        # 6) Execute the query\n",
    "        try:\n",
    "            df = pd.read_sql(query, self.config.engine)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"SQL Execution Failed: {e}\")\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 2] SQL Query executed. Here's df.head():\")\n",
    "        self._log(df.head().to_string())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_python_prompt(self, user_query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Given the user query and a pandas DataFrame, produce a textual prompt describing\n",
    "        how to perform the Python computations that answer the query.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Generating Python prompt...\")\n",
    "\n",
    "        prompt = f''' \n",
    "        Given a user query and a pandas dataframe with the relevant data, only write \n",
    "        CODE DESCRIPTION: CODE DESCRIPTION, where CODE DESCRIPTION is a prompt \n",
    "        that (a) gives a high level goal, (b) gives a step by step method that describes how \n",
    "        to take the dataframe (called df) and write python code to perform \n",
    "        relevant computations to answer the user query. Don't write any code, but write \n",
    "        the prompt such that if an independent python master with access to df + your instructions could \n",
    "        easily answer the original user query. Be specific about how to perform the computations,\n",
    "        including any relevant math, what functions to use (assume pandas, numpy access). \n",
    "\n",
    "        Example User Query: Calculate the correlation between 7 year treasury yields and stocks close over the last 30 days\n",
    "        in the table.\n",
    "        Example Dataframe (df.head()): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Answer:\n",
    "        CODE DESCRIPTION: \n",
    "        Overall Goal: Calculate correlation between treasury_yield_7_year and stock close over the most recent 30 days.\n",
    "        Step 1: take df with cols treasury_yield_7_year, stock_close, date \n",
    "        Step 2: filter df by sorting by date and taking only the most recent 30 days\n",
    "        Step 3: calculate correlation between treasury_yield_7_year and stock_close using pandas corr function.\n",
    "\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        User Query: {user_query}\n",
    "        '''\n",
    "        try:\n",
    "            py_prompt = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python prompt failed: {e}\")\n",
    "\n",
    "        if not isinstance(py_prompt, str) or not py_prompt.strip():\n",
    "            raise ValueError(\"Python Prompt Generation Failed: Did not receive a valid string from LLM.\")\n",
    "        \n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Completed: Python prompt generated.\")\n",
    "        self._log(\"Generated Python Prompt:\")\n",
    "        self._log(py_prompt)\n",
    "\n",
    "        return py_prompt\n",
    "\n",
    "    def execute_python(self, py_prompt: str, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate Python code based on the py_prompt, execute it, and return the 'result' variable.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Generating and executing Python code...\")\n",
    "\n",
    "        py_code_request = f''' \n",
    "        Given a pandas dataframe df and a description to perform a specific computation, \n",
    "        generate syntactically correct python code wrapped in python QUERY` that takes \n",
    "        the raw dataframe and performs any computations to fully answer the user's query. \n",
    "        Assume access to NumPy (v{np.__version__}), Pandas (v{pd.__version__}) and that \n",
    "        the dataframe is called df. The output of the code should be the variable that \n",
    "        contains the result of the user's query (call this variable result)\n",
    "\n",
    "        Example Dataframe (df): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Prompt: Given df with cols treasury_yield_7_year, stock_close, date, use pandas corr function\n",
    "        to compute the correlation between treasury_yield_7_year and stock close. \n",
    "\n",
    "        Example Labeled Answer: \n",
    "        ```\n",
    "        python\n",
    "        ### calculate corr btwn 7yr tsy and stock closes \n",
    "        df     = df.sort_values('date')[:30]\n",
    "        result = df['treasury_yield_7_year'].corr(df['stock_close'])    \n",
    "        ```\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        Prompt: {py_prompt}\n",
    "        '''\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(py_code_request).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python code generation failed: {e}\")\n",
    "\n",
    "        # Extract python code block\n",
    "        try:\n",
    "            code = extract_query(llm_response, type='python')\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Python Code Extraction Failed: {e}\")\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"Generated Python Code:\")\n",
    "        self._log(code)\n",
    "\n",
    "        namespace = {'pd': pd, 'np': np, 'df': df, 'plt': plt}\n",
    "        try:\n",
    "            exec(code, namespace)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Python Execution Failed: error executing python: {e}\")\n",
    "\n",
    "        result = namespace.get('result', None)\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Result from executed code:\")\n",
    "        self._log(str(result))\n",
    "\n",
    "        return result\n",
    "\n",
    "run = True  \n",
    "if run:\n",
    "    config     = Config()\n",
    "    agent      = BasicAgent(config)\n",
    "    user_queries = ['''For the day with the lowest ratio of 5y tsy yield to 10y tsy yield \n",
    "    among days where USD to GBP was greater than 0.75, calculate the percentage difference \n",
    "    between the EUR equivalent of the close price and the JPY equivalent of the open price \n",
    "    in the ohlc table.''','''On the day where the absolute difference between 7y tsy yield \n",
    "    and 10y tsy yield was maximum, compute the ratio of the USD equivalent of the difference \n",
    "    between high and low prices in the ohlc table to the product of USD:EUR and USD:JPY \n",
    "    for that day.''', '''\"For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''] \n",
    "\n",
    "    # user_query = '''For s in [1,2], of the days where the stock price \n",
    "    # movement := close - open was more than s std deviations from the mean, look at the distribution \n",
    "    # of 7yr tsy yield - 5yr tsy yield. To visualize this, assume access to matplotlib.pyplot as plt and \n",
    "    # make 2 plots, the left where s = 1 and a histogram of 7yr - 5yr tsy yields with lines at 25 percentile,\n",
    "    # 50th percentile, 75th, and then right same with s=2. Then return the median when s=1. \n",
    "    # '''\n",
    "    for user_query in user_queries[:1]:\n",
    "        result = agent.run(user_query)  \n",
    "        print(\"Final numeric result:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
