{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from agent import Agent, Config\n",
    "from helper import get_paths, extract_query, get_schema_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "[STEP 0] Starting 'run' method.\n",
      "User Query:\n",
      "For the day with the lowest ratio of 5y tsy yield to 10y tsy yield \n",
      "    among days where USD to GBP was greater than 0.75, calculate the percentage difference \n",
      "    between the EUR equivalent of the close price and the JPY equivalent of the open price \n",
      "    in the ohlc table.\n",
      "==================================================\n",
      "[STEP 1] Generating SQL JSON from user query...\n",
      "==================================================\n",
      "LLM Response (raw):\n",
      "```json\n",
      "{\n",
      "  \"tables\": [\n",
      "    {\n",
      "      \"name\": \"treasury_yields\",\n",
      "      \"alias\": \"tsy\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"tsy_date\",\n",
      "          \"keep\": true\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"yield_5_year\",\n",
      "          \"alias\": \"tsy_yield_5_year\",\n",
      "          \"keep\": true\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"yield_10_year\",\n",
      "          \"alias\": \"tsy_yield_10_year\",\n",
      "          \"keep\": true\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"fxrates\",\n",
      "      \"alias\": \"fx\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"fx_date\",\n",
      "          \"keep\": false\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_eur\",\n",
      "          \"alias\": \"usd_to_eur\",\n",
      "          \"keep\": true\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_gbp\",\n",
      "          \"alias\": \"usd_to_gbp\",\n",
      "          \"keep\": true\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"usd_to_jpy\",\n",
      "          \"alias\": \"usd_to_jpy\",\n",
      "          \"keep\": true\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"ohlc\",\n",
      "      \"alias\": \"ohlc\",\n",
      "      \"columns\": [\n",
      "        {\n",
      "          \"original_name\": \"date\",\n",
      "          \"alias\": \"ohlc_date\",\n",
      "          \"keep\": false\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"open\",\n",
      "          \"alias\": \"stock_open\",\n",
      "          \"keep\": true\n",
      "        },\n",
      "        {\n",
      "          \"original_name\": \"close\",\n",
      "          \"alias\": \"stock_close\",\n",
      "          \"keep\": true\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"joins\": [\n",
      "    {\n",
      "      \"left_table_alias\": \"tsy\",\n",
      "      \"right_table_alias\": \"fx\",\n",
      "      \"left_column\": \"date\",\n",
      "      \"right_column\": \"date\",\n",
      "      \"join_type\": \"inner\"\n",
      "    },\n",
      "    {\n",
      "      \"left_table_alias\": \"fx\",\n",
      "      \"right_table_alias\": \"ohlc\",\n",
      "      \"left_column\": \"fx_date\",\n",
      "      \"right_column\": \"date\",\n",
      "      \"join_type\": \"inner\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "'BasicAgent' object has no attribute 'schema'\n",
      "//////////////////////////////////////////////////\n",
      "==================================================\n",
      "[STEP 0] Starting 'run' method.\n",
      "User Query:\n",
      "On the day where the absolute difference between 7y tsy yield \n",
      "    and 10y tsy yield was maximum, compute the ratio of the USD equivalent of the difference \n",
      "    between high and low prices in the ohlc table to the product of USD:EUR and USD:JPY \n",
      "    for that day.\n",
      "==================================================\n",
      "[STEP 1] Generating SQL JSON from user query...\n",
      "LLM invocation for SQL JSON failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "//////////////////////////////////////////////////\n",
      "==================================================\n",
      "[STEP 0] Starting 'run' method.\n",
      "User Query:\n",
      "\"For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
      "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
      "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
      "    treasury yields\n",
      "==================================================\n",
      "[STEP 1] Generating SQL JSON from user query...\n",
      "LLM invocation for SQL JSON failed: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "//////////////////////////////////////////////////\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class BasicAgent(Agent):\n",
    "\n",
    "    def __init__(self, config: Config, log_data=True):\n",
    "        super().__init__(config)\n",
    "        self.log_data = log_data\n",
    "        self.path_map = get_paths()  \n",
    "\n",
    "    def _log(self, message: str):\n",
    "        \"\"\"\n",
    "        Helper method to handle logging to both console and a log file.\n",
    "        Appends each message as a new line.\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        if self.log_data:\n",
    "            try:\n",
    "                with open(self.path_map['log'], 'a') as f:\n",
    "                    f.write(message + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not write to log file: {e}\")\n",
    "\n",
    "    def run(self, user_query: str) -> float:\n",
    "        \"\"\"\n",
    "        Takes a user query string, runs it through:\n",
    "          get_sql_json -> compile_sql -> get_python_prompt -> execute_python\n",
    "        and returns a float result.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 0] Starting 'run' method.\")\n",
    "        self._log(f\"User Query:\\n{user_query}\")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # 1) Convert the user query to SQL JSON\n",
    "        sql_json = self.get_sql_json(user_query)\n",
    "\n",
    "        # 2) Compile SQL and fetch data into a dataframe\n",
    "        df = self.compile_sql(sql_json)\n",
    "\n",
    "        # 3) Generate a Python prompt describing the next steps\n",
    "        py_prompt = self.get_python_prompt(user_query, df)\n",
    "\n",
    "        # 4) Execute the described Python steps and retrieve the result\n",
    "        result = self.execute_python(py_prompt, df)\n",
    "\n",
    "        end = time.time()\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(f\"[STEP 5] Completed run in {round(end - start, 2)} seconds.\\n\")\n",
    "\n",
    "        # Validate final result is float-like\n",
    "        if not isinstance(result, (int, float)):\n",
    "            raise ValueError(f\"Python Execution Failed: the final result must be a float or int, instead got {type(result)}\")\n",
    "        \n",
    "        return float(result)\n",
    "\n",
    "    def validate_sql_json(self, sql_json: dict):\n",
    "        \"\"\"\n",
    "        Validates a JSON structure that specifies:\n",
    "        1) A list of tables with name, alias, and columns\n",
    "        2) A list of joins describing how the tables are joined\n",
    "\n",
    "        - Checks if the referenced tables and columns exist in the schema.\n",
    "        - Checks if join column types match.\n",
    "        - Joins must use one of the valid join types: {\"inner\", \"left\", \"right\", \"outer\"}.\n",
    "\n",
    "        Returns:\n",
    "            (True, \"\") if valid\n",
    "            (False, <error_message>) if invalid\n",
    "        \"\"\"\n",
    "        # 1) Basic structure checks\n",
    "        if \"tables\" not in sql_json:\n",
    "            return False, \"Missing top-level 'tables' key.\"\n",
    "        if \"joins\" not in sql_json:\n",
    "            return False, \"Missing top-level 'joins' key.\"\n",
    "\n",
    "        # Gather known table aliases for join checks\n",
    "        table_aliases = {}\n",
    "\n",
    "        # 2) Validate each table + columns\n",
    "        for tbl_obj in sql_json[\"tables\"]:\n",
    "            # required fields: name, alias, columns\n",
    "            if \"name\" not in tbl_obj or \"alias\" not in tbl_obj or \"columns\" not in tbl_obj:\n",
    "                return False, \"Each table object must have 'name', 'alias', and 'columns'.\"\n",
    "\n",
    "            tbl_name = tbl_obj[\"name\"]\n",
    "            tbl_alias = tbl_obj[\"alias\"]\n",
    "            if tbl_name not in self.schema:\n",
    "                return False, f\"Table '{tbl_name}' not found in schema.\"\n",
    "\n",
    "            table_aliases[tbl_alias] = tbl_name\n",
    "\n",
    "            # Validate columns\n",
    "            for col in tbl_obj[\"columns\"]:\n",
    "                if \"original_name\" not in col:\n",
    "                    return False, \"Each column object must have 'original_name'.\"\n",
    "                if \"alias\" not in col:\n",
    "                    return False, \"Each column object must have 'alias'.\"\n",
    "                if \"keep\" not in col:\n",
    "                    return False, \"Each column object must have 'keep' (boolean).\"\n",
    "\n",
    "                col_name = col[\"original_name\"]\n",
    "                if col_name not in self.schema[tbl_name][\"columns\"]:\n",
    "                    return False, f\"Column '{col_name}' does not exist in table '{tbl_name}'.\"\n",
    "\n",
    "        # 3) Validate joins\n",
    "        valid_join_types = {\"inner\", \"left\", \"right\", \"outer\"}\n",
    "        for j in sql_json[\"joins\"]:\n",
    "            # required fields: left_table_alias, right_table_alias, left_column, right_column, join_type\n",
    "            required_keys = [\n",
    "                \"left_table_alias\",\n",
    "                \"right_table_alias\",\n",
    "                \"left_column\",\n",
    "                \"right_column\",\n",
    "                \"join_type\"\n",
    "            ]\n",
    "            for k in required_keys:\n",
    "                if k not in j:\n",
    "                    return False, f\"Join object must have '{k}'.\"\n",
    "\n",
    "            lt_alias = j[\"left_table_alias\"]\n",
    "            rt_alias = j[\"right_table_alias\"]\n",
    "            lt_col = j[\"left_column\"]\n",
    "            rt_col = j[\"right_column\"]\n",
    "            jtype = j[\"join_type\"]\n",
    "\n",
    "            # Check table alias existence\n",
    "            if lt_alias not in table_aliases:\n",
    "                return False, f\"Join references unknown table alias '{lt_alias}'.\"\n",
    "            if rt_alias not in table_aliases:\n",
    "                return False, f\"Join references unknown table alias '{rt_alias}'.\"\n",
    "\n",
    "            # Check valid join type\n",
    "            if jtype not in valid_join_types:\n",
    "                return False, f\"Invalid join type '{jtype}'. Must be one of {valid_join_types}.\"\n",
    "\n",
    "            # Check column existence in schema\n",
    "            lt_table = table_aliases[lt_alias]\n",
    "            rt_table = table_aliases[rt_alias]\n",
    "            if lt_col not in self.schema[lt_table][\"columns\"]:\n",
    "                return False, f\"Column '{lt_col}' not found in table '{lt_table}'.\"\n",
    "            if rt_col not in self.schema[rt_table][\"columns\"]:\n",
    "                return False, f\"Column '{rt_col}' not found in table '{rt_table}'.\"\n",
    "\n",
    "            # Optional: check column types match\n",
    "            lt_type = self.schema[lt_table][\"columns\"][lt_col]\n",
    "            rt_type = self.schema[rt_table][\"columns\"][rt_col]\n",
    "            if lt_type != rt_type:\n",
    "                return False, (\n",
    "                    f\"Join column type mismatch: '{lt_table}.{lt_col}' is '{lt_type}' while \"\n",
    "                    f\"'{rt_table}.{rt_col}' is '{rt_type}'.\"\n",
    "                )\n",
    "\n",
    "        # If everything is valid\n",
    "        return True, \"\"\n",
    "\n",
    "    def get_sql_json(self, user_query: str) -> dict:\n",
    "        \"\"\"\n",
    "        Takes a user query and asks the LLM to produce a JSON specifying which tables/columns to pull.\n",
    "        Validates the JSON structure and join types.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 1] Generating SQL JSON from user query...\")\n",
    "\n",
    "        schema_context = get_schema_context(self.config)\n",
    "        prompt = f'''Given a user query and a SQLite database schema, return ONLY a valid JSON describing the \n",
    "        data required to answer the user query. The JSON should be parsable and adhere to proper JSON syntax.\n",
    "\n",
    "        Instructions:\n",
    "        2. Ensure column names and new column names are strings, and there are no extraneous characters.\n",
    "        3. Be mindful of how many days of data to pull, as certain queries may specify n days but \n",
    "        require more than n to compute the result.\n",
    "        4. Avoid creating new columns or performing calculations; these will be handled in later steps.\n",
    "        5. Ensure new column names are self-explanatory and clear for what they are, not what they will be.\n",
    "        For example do treasury_yield_7_year instead of something like 7y_yield, but don't do\n",
    "        treasury_price_7_year, even if eventually that column will be transformed into price.\n",
    "        6. keep is relevant for cols where joins are performed- for example if there is an inner join between\n",
    "        two dates, these columns are needed to perform the join, but one is irrelevant in the end (one is keep=False)\n",
    "\n",
    "        Answer ONLY with a JSON in this format:\n",
    "        {{\n",
    "  \"tables\": [\n",
    "    {{\n",
    "      \"name\": \"<db_table_name>\",\n",
    "      \"alias\": \"<alias>\",\n",
    "      \"columns\": [\n",
    "        {{\n",
    "          \"original_name\": \"<col_name_in_db>\",\n",
    "          \"alias\": \"<col_alias_in_output>\",\n",
    "          \"keep\": true // or false\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"joins\": [\n",
    "    {{\n",
    "      \"left_table_alias\": \"<alias>\",\n",
    "      \"right_table_alias\": \"<alias>\",\n",
    "      \"left_column\": \"<col_name_in_db>\", \n",
    "      \"right_column\": \"<col_name_in_db>\",\n",
    "      \"join_type\": \"inner\" // or outer, left, right\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "        Constraints:\n",
    "        - Join types must be one of: \"inner\", \"left\", \"right\", \"outer\".\n",
    "        - Join column names must be the OLD name, not the NEW name \n",
    "        - Joins will be applied in order of the json. Note the order does matter here. For example \n",
    "        if the first join is inner(A,B) then next is outer(B, C), what is really happening is \n",
    "        outer(C, inner(A,B)), i.e. not inner(A, outer(B,C))\n",
    "\n",
    "        Database Schema: {schema_context}\n",
    "\n",
    "        Example User Query: Calculate the correlation between 7-year treasury yields and stocks' \n",
    "        close prices over the last 30 days.\n",
    "\n",
    "        Example Labeled Answer:\n",
    "        ```\n",
    "        json\n",
    "        {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"ohlc\",\n",
    "        \"alias\": \"ohlc\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"ohlc_date\",\n",
    "            \"keep\": true\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"close\",\n",
    "            \"alias\": \"stock_close\",\n",
    "            \"keep\": true\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "        {{\n",
    "        \"name\": \"treasury_yields\",\n",
    "        \"alias\": \"treasury_yields\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"tsy_date\",\n",
    "            \"keep\": false\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_7_year\",\n",
    "            \"alias\": \"tsy_yield_7_year\",\n",
    "            \"keep\": true\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "    ],\n",
    "    \"joins\": [\n",
    "        {{\n",
    "        \"left_table_alias\": \"ohlc\",\n",
    "        \"right_table_alias\": \"treasury_yields\",\n",
    "        \"left_column\": \"date\",\n",
    "        \"right_column\": \"date\",\n",
    "        \"join_type\": \"inner\"\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "    ```\n",
    "        Answer for the following user query: {user_query}\n",
    "        ''' \n",
    "\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for SQL JSON failed: {e}\")\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"LLM Response (raw):\")\n",
    "        self._log(llm_response)\n",
    "\n",
    "        try:\n",
    "            sql_json_str = extract_query(llm_response, type='json')\n",
    "            sql_json = json.loads(sql_json_str)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"SQL JSON Extraction Failed (2nd attempt): {e}\")\n",
    "\n",
    "        is_valid, err_msg = self.validate_sql_json(sql_json)\n",
    "        if not is_valid:\n",
    "            raise ValueError(f\"LLM failed to fix the JSON: {err_msg}\")\n",
    "\n",
    "        return sql_json\n",
    "\n",
    "    \n",
    "    def compile_sql(self, sql_json: dict) -> str:\n",
    "        \"\"\"\n",
    "        Transforms the validated JSON (with no filters) into a SQL SELECT statement.\n",
    "\n",
    "        The JSON must have:\n",
    "        {\n",
    "        \"tables\": [\n",
    "            {\n",
    "            \"name\": \"ohlc\",\n",
    "            \"alias\": \"ohlc\",\n",
    "            \"columns\": [\n",
    "                {\n",
    "                \"original_name\": \"date\",\n",
    "                \"alias\": \"ohlc_date\",\n",
    "                \"keep\": true\n",
    "                },\n",
    "                ...\n",
    "            ]\n",
    "            },\n",
    "            ...\n",
    "        ],\n",
    "        \"joins\": [\n",
    "            {\n",
    "            \"left_table_alias\": \"ohlc\",\n",
    "            \"right_table_alias\": \"treasury_yields\",\n",
    "            \"left_column\": \"date\",\n",
    "            \"right_column\": \"date\",\n",
    "            \"join_type\": \"inner\"\n",
    "            }\n",
    "        ]\n",
    "        }\n",
    "\n",
    "        Returns:\n",
    "            A string representing the SQL query (SELECT + FROM + JOIN).\n",
    "        \"\"\"\n",
    "        # 1) Build SELECT clause\n",
    "        select_parts = []\n",
    "        table_alias_map = {}\n",
    "        for tbl in sql_json[\"tables\"]:\n",
    "            table_alias_map[tbl[\"alias\"]] = tbl[\"name\"]\n",
    "            for col in tbl[\"columns\"]:\n",
    "                if col[\"keep\"] is True:\n",
    "                    original = col[\"original_name\"]\n",
    "                    alias = col[\"alias\"]\n",
    "                    select_parts.append(f'\"{tbl[\"alias\"]}\".\"{original}\" AS \"{alias}\"')\n",
    "\n",
    "        if not select_parts:\n",
    "            raise ValueError(\"No columns to keep in the final query.\")\n",
    "\n",
    "        select_clause = \",\\n    \".join(select_parts)\n",
    "\n",
    "        # 2) Build FROM + JOIN\n",
    "        joins = sql_json.get(\"joins\", [])\n",
    "        if len(joins) == 0:\n",
    "            # No joins: just use the first table\n",
    "            if len(sql_json[\"tables\"]) == 0:\n",
    "                raise ValueError(\"No tables available to compile SQL.\")\n",
    "            first_tbl = sql_json[\"tables\"][0]\n",
    "            from_clause = f'\"{first_tbl[\"name\"]}\" \"{first_tbl[\"alias\"]}\"'\n",
    "        else:\n",
    "            # Use the first join's left_table_alias as the \"base\"\n",
    "            base_alias = joins[0][\"left_table_alias\"]\n",
    "            base_table_name = table_alias_map[base_alias]\n",
    "            from_clause = f'\"{base_table_name}\" \"{base_alias}\"'\n",
    "            for j in joins:\n",
    "                right_table_name = table_alias_map[j[\"right_table_alias\"]]\n",
    "                join_type = j[\"join_type\"].upper()\n",
    "                from_clause += (\n",
    "                    f'\\n{join_type} JOIN \"{right_table_name}\" \"{j[\"right_table_alias\"]}\" '\n",
    "                    f'ON \"{j[\"left_table_alias\"]}\".\"{j[\"left_column\"]}\" = '\n",
    "                    f'\"{j[\"right_table_alias\"]}\".\"{j[\"right_column\"]}\"'\n",
    "                )\n",
    "\n",
    "        # 3) Construct final SQL\n",
    "        query = f\"\"\"\n",
    "    SELECT\n",
    "        {select_clause}\n",
    "    FROM {from_clause}\n",
    "    \"\"\".strip()\n",
    "\n",
    "        return query\n",
    "\n",
    "\n",
    "    def get_python_prompt(self, user_query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Given the user query and a pandas DataFrame, produce a textual prompt describing\n",
    "        how to perform the Python computations that answer the query.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Generating Python prompt...\")\n",
    "\n",
    "        prompt = f''' \n",
    "        Given a user query and a pandas dataframe with the relevant data, only write \n",
    "        CODE DESCRIPTION: CODE DESCRIPTION, where CODE DESCRIPTION is a prompt \n",
    "        that (a) gives a high level goal, (b) gives a step by step method that describes how \n",
    "        to take the dataframe (called df) and write python code to perform \n",
    "        relevant computations to answer the user query. Don't write any code, but write \n",
    "        the prompt such that if an independent python master with access to df + your instructions could \n",
    "        easily answer the original user query. Be specific about how to perform the computations,\n",
    "        including any relevant math, what functions to use (assume pandas, numpy access). \n",
    "\n",
    "        Example User Query: Calculate the correlation between 7 year treasury yields and stocks close over the last 30 days\n",
    "        in the table.\n",
    "        Example Dataframe (df.head()): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Answer:\n",
    "        CODE DESCRIPTION: \n",
    "        Overall Goal: Calculate correlation between treasury_yield_7_year and stock close over the most recent 30 days.\n",
    "        Step 1: take df with cols treasury_yield_7_year, stock_close, date \n",
    "        Step 2: filter df by sorting by date and taking only the most recent 30 days\n",
    "        Step 3: calculate correlation between treasury_yield_7_year and stock_close using pandas corr function.\n",
    "\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        User Query: {user_query}\n",
    "        '''\n",
    "        try:\n",
    "            py_prompt = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python prompt failed: {e}\")\n",
    "\n",
    "        if not isinstance(py_prompt, str) or not py_prompt.strip():\n",
    "            raise ValueError(\"Python Prompt Generation Failed: Did not receive a valid string from LLM.\")\n",
    "        \n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Completed: Python prompt generated.\")\n",
    "        self._log(\"Generated Python Prompt:\")\n",
    "        self._log(py_prompt)\n",
    "\n",
    "        return py_prompt\n",
    "\n",
    "    def execute_python(self, py_prompt: str, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate Python code based on the py_prompt, execute it, and return the 'result' variable.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Generating and executing Python code...\")\n",
    "\n",
    "        py_code_request = f''' \n",
    "        Given a pandas dataframe df and a description to perform a specific computation, \n",
    "        generate syntactically correct python code wrapped in python QUERY` that takes \n",
    "        the raw dataframe and performs any computations to fully answer the user's query. \n",
    "        Assume access to NumPy (v{np.__version__}), Pandas (v{pd.__version__}) and that \n",
    "        the dataframe is called df. The output of the code should be the variable that \n",
    "        contains the result of the user's query (call this variable result)\n",
    "\n",
    "        Example Dataframe (df): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Prompt: Given df with cols treasury_yield_7_year, stock_close, date, use pandas corr function\n",
    "        to compute the correlation between treasury_yield_7_year and stock close. \n",
    "\n",
    "        Example Labeled Answer: \n",
    "        ```\n",
    "        python\n",
    "        ### calculate corr btwn 7yr tsy and stock closes \n",
    "        df     = df.sort_values('date')[:30]\n",
    "        result = df['treasury_yield_7_year'].corr(df['stock_close'])    \n",
    "        ```\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        Prompt: {py_prompt}\n",
    "        '''\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(py_code_request).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python code generation failed: {e}\")\n",
    "\n",
    "        # Extract python code block\n",
    "        try:\n",
    "            code = extract_query(llm_response, type='python')\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Python Code Extraction Failed: {e}\")\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"Generated Python Code:\")\n",
    "        self._log(code)\n",
    "\n",
    "        namespace = {'pd': pd, 'np': np, 'df': df, 'plt': plt}\n",
    "        try:\n",
    "            exec(code, namespace)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Python Execution Failed: error executing python: {e}\")\n",
    "\n",
    "        result = namespace.get('result', None)\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Result from executed code:\")\n",
    "        self._log(str(result))\n",
    "\n",
    "        return result\n",
    "\n",
    "run = True  \n",
    "if run:\n",
    "    config     = Config()\n",
    "    agent      = BasicAgent(config)\n",
    "    user_queries = ['''For the day with the lowest ratio of 5y tsy yield to 10y tsy yield \n",
    "    among days where USD to GBP was greater than 0.75, calculate the percentage difference \n",
    "    between the EUR equivalent of the close price and the JPY equivalent of the open price \n",
    "    in the ohlc table.''','''On the day where the absolute difference between 7y tsy yield \n",
    "    and 10y tsy yield was maximum, compute the ratio of the USD equivalent of the difference \n",
    "    between high and low prices in the ohlc table to the product of USD:EUR and USD:JPY \n",
    "    for that day.''', '''\"For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''] \n",
    "\n",
    "    # user_query = '''For s in [1,2], of the days where the stock price \n",
    "    # movement := close - open was more than s std deviations from the mean, look at the distribution \n",
    "    # of 7yr tsy yield - 5yr tsy yield. To visualize this, assume access to matplotlib.pyplot as plt and \n",
    "    # make 2 plots, the left where s = 1 and a histogram of 7yr - 5yr tsy yields with lines at 25 percentile,\n",
    "    # 50th percentile, 75th, and then right same with s=2. Then return the median when s=1. \n",
    "    # '''\n",
    "    for user_query in user_queries:\n",
    "        try:\n",
    "            result = agent.run(user_query)  \n",
    "            print(\"Final numeric result:\", result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        print(f'/' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
