{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic SQL Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from helper import get_paths\n",
    "\n",
    "class Config:\n",
    "    \"\"\"SQL agent config\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_model = 'gpt-4-1106-preview',\n",
    "        temperature  = 0.7\n",
    "        ):\n",
    "        path_map  = get_paths()\n",
    "        env_fpath = path_map['env']\n",
    "        sql_fpath = path_map['sql']\n",
    "\n",
    "        load_dotenv(env_fpath)\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=openai_model,\n",
    "            temperature=temperature,\n",
    "            api_key=openai_api_key\n",
    "            )\n",
    "        self.db     = SQLDatabase.from_uri(f\"sqlite:///{sql_fpath}\")\n",
    "        self.engine = create_engine(f\"sqlite:///{sql_fpath}\")\n",
    "\n",
    "config = Config()\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE SCHEMA:\n",
      "Table: fxrates\n",
      "\n",
      "CREATE TABLE fxrates (\n",
      "\tdate TIMESTAMP, \n",
      "\tusd_to_eur REAL, \n",
      "\tusd_to_gbp REAL, \n",
      "\tusd_to_jpy REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from fxrates table:\n",
      "date\tusd_to_eur\tusd_to_gbp\tusd_to_jpy\n",
      "2020-01-01 00:00:00\t0.9552158220469241\t0.7442134597684561\t178.67087145000016\n",
      "2020-01-02 00:00:00\t0.9537308256723278\t0.7785893129739717\t149.17956918593097\n",
      "2020-01-03 00:00:00\t0.9883022675224316\t0.8852523415853203\t145.90253010300282\n",
      "*/\n",
      "\n",
      "Table: ohlc\n",
      "\n",
      "CREATE TABLE ohlc (\n",
      "\tdate TIMESTAMP, \n",
      "\topen REAL, \n",
      "\thigh REAL, \n",
      "\tlow REAL, \n",
      "\tclose REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ohlc table:\n",
      "date\topen\thigh\tlow\tclose\n",
      "2020-01-01 00:00:00\t97.84704724718776\t122.24383711340477\t55.44555344062485\t92.24425183108863\n",
      "2020-01-02 00:00:00\t92.1025462060139\t123.51768361972003\t66.15905516369102\t95.32120830941909\n",
      "2020-01-03 00:00:00\t106.36100005515581\t128.19239423274277\t55.33471311840124\t86.26686713329055\n",
      "*/\n",
      "\n",
      "Table: treasury_yields\n",
      "\n",
      "CREATE TABLE treasury_yields (\n",
      "\tdate TIMESTAMP, \n",
      "\tyield_5_year REAL, \n",
      "\tyield_7_year REAL, \n",
      "\tyield_10_year REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from treasury_yields table:\n",
      "date\tyield_5_year\tyield_7_year\tyield_10_year\n",
      "2020-01-01 00:00:00\t1.5456939689216451\t3.5331408648502958\t2.420871768439542\n",
      "2020-01-02 00:00:00\t2.2450376346705516\t2.461980928007222\t2.566896305964475\n",
      "2020-01-03 00:00:00\t1.3979936885073319\t4.226303400434457\t3.327935993451753\n",
      "*/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def get_schema_context(config=config, tbls_to_exclude=[]):\n",
    "    db = config.db\n",
    "    tables = db.get_usable_table_names()\n",
    "\n",
    "    schema_lines = []\n",
    "    for table in tables:\n",
    "        if table not in tbls_to_exclude:\n",
    "            table_info = db.get_table_info([table])\n",
    "            schema_lines.append(f\"Table: {table}\\n{table_info}\\n\")\n",
    "\n",
    "    schema_context = (\"DATABASE SCHEMA:\\n\" + \"\\n\".join(schema_lines))\n",
    "    return schema_context\n",
    "\n",
    "def extract_query(response, type='sql'):\n",
    "    pattern = rf\"```{type}\\s+([\\s\\S]*?)\\s+```\"\n",
    "    match   = re.search(pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"Extracting query of type {type} failed: returning response.strip():\\n{response.strip()}\")\n",
    "        return response.strip()\n",
    "\n",
    "if verbose:\n",
    "    print(get_schema_context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Tables JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate the correlation between 7-year treasury yields and stocks' close prices over the last 30 days.\n",
      "==============================\n",
      "        \n",
      "    ```json\n",
      "    {{\n",
      "    \"tables\": [\n",
      "        {{\n",
      "        \"name\": \"treasury_yields\",\n",
      "        \"columns\": [\n",
      "            {{\n",
      "            \"original_name\": \"date\",\n",
      "            \"alias\": \"yield_date\"\n",
      "            }},\n",
      "            {{\n",
      "            \"original_name\": \"yield_5_year\",\n",
      "            \"alias\": \"yield_5y_tsy\"\n",
      "            }},\n",
      "            {{\n",
      "            \"original_name\": \"yield_10_year\",\n",
      "            \"alias\": \"yield_10y_tsy\"\n",
      "            }}\n",
      "        ]\n",
      "        }},\n",
      "    }}\n",
      "    ```\n",
      "    \n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "### one shot \n",
    "\n",
    "template = ''' \n",
    "    ```json\n",
    "    {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"<db_table_name>\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"<col_name_in_db>\",\n",
    "            \"alias\": \"<col_alias_in_output>\"\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "    ]}}\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "examples = [{\n",
    "    \"input\" : \"Calculate the correlation between 7-year treasury yields and stocks' close prices over the last 30 days.\",\n",
    "    \"output\" : '''        \n",
    "    ```json\n",
    "    {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"treasury_yields\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"yield_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_5_year\",\n",
    "            \"alias\": \"yield_5y_tsy\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_10_year\",\n",
    "            \"alias\": \"yield_10y_tsy\"\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "    }}\n",
    "    ```\n",
    "    '''\n",
    "}]\n",
    "\n",
    "for example in examples:\n",
    "    print(example['input'])\n",
    "    print(f'=' * 30)\n",
    "    print(example['output'])\n",
    "    print(f'=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "def get_tables_json_str(user_query, config=config, error_msg=None):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('human', '{input}'), ('ai', '{output}')]\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "    )\n",
    "    schema_context = get_schema_context(config)\n",
    "    system_message  = f'''Given a user query and a SQLite database schema, return ONLY a valid JSON describing the data required to answer the user query. The JSON should be parsable and adhere to proper JSON syntax. Answer ONLY with a JSON in this format: {template}\n",
    "    Here is the database schema: {schema_context}'''\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', f'{system_message}'),\n",
    "            few_shot_prompt,\n",
    "            ('human', '{input}'),\n",
    "        ]\n",
    "    )\n",
    "    chain = final_prompt | config.llm \n",
    "    llm_response = chain.invoke({'input' : user_query}).content \n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = f'''For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''\n",
    "llm_response = get_tables_json_str(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tables': [{'name': 'fxrates', 'columns': [{'original_name': 'date', 'alias': 'fx_date'}, {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur'}, {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp'}, {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy'}]}, {'name': 'ohlc', 'columns': [{'original_name': 'date', 'alias': 'ohlc_date'}, {'original_name': 'open', 'alias': 'open_usd'}, {'original_name': 'high', 'alias': 'high_usd'}, {'original_name': 'close', 'alias': 'close_usd'}]}, {'name': 'treasury_yields', 'columns': [{'original_name': 'date', 'alias': 'ty_date'}, {'original_name': 'yield_5_year', 'alias': 'yield_5_year'}, {'original_name': 'yield_7_year', 'alias': 'yield_7_year'}, {'original_name': 'yield_10_year', 'alias': 'yield_10_year'}]}]}\n"
     ]
    }
   ],
   "source": [
    "tables_json = json.loads(extract_query(llm_response, type='json'))\n",
    "print(tables_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Joins JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the day with the lowest ratio of 5y tsy yield to 10y tsy yield among days where USD to GBP was greater than 0.75, calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price in the ohlc table.\n",
      "==============================\n",
      " \n",
      "    ```json\n",
      "        {{\n",
      "        \"tables\": [\n",
      "          {{\n",
      "            \"name\": \"treasury_yields\",\n",
      "            \"columns\": [\n",
      "              {{\n",
      "                \"original_name\": \"date\",\n",
      "                \"alias\": \"yield_date\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"yield_5_year\",\n",
      "                \"alias\": \"yield_5y_tsy\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"yield_10_year\",\n",
      "                \"alias\": \"yield_10y_tsy\"\n",
      "              }}\n",
      "            ]\n",
      "          }},\n",
      "          {{\n",
      "            \"name\": \"fxrates\",\n",
      "            \"columns\": [\n",
      "              {{\n",
      "                \"original_name\": \"date\",\n",
      "                \"alias\": \"fx_date\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"usd_to_gbp\",\n",
      "                \"alias\": \"usd_gbp\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"usd_to_eur\",\n",
      "                \"alias\": \"usd_eur\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"usd_to_jpy\",\n",
      "                \"alias\": \"usd_jpy\"\n",
      "              }}\n",
      "            ]\n",
      "          }},\n",
      "          {{\n",
      "            \"name\": \"ohlc\",\n",
      "            \"columns\": [\n",
      "              {{\n",
      "                \"original_name\": \"date\",\n",
      "                \"alias\": \"ohlc_date\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"open\",\n",
      "                \"alias\": \"stock_open\"\n",
      "              }},\n",
      "              {{\n",
      "                \"original_name\": \"close\",\n",
      "                \"alias\": \"stock_close\"\n",
      "              }}\n",
      "            ]\n",
      "          }}\n",
      "        ]\n",
      "      }}\n",
      "    \n",
      "==============================\n",
      "\n",
      "    ```json\n",
      "      {{\n",
      "      \"join_node\": {{\n",
      "        \"join_type\": \"inner\",\n",
      "        \"left\": {{\n",
      "          \"table\": \"treasury_yields\"\n",
      "        }},\n",
      "        \"right\": {{\n",
      "          \"join_type\": \"inner\",\n",
      "          \"left\": {{\n",
      "            \"table\": \"ohlc\"\n",
      "          }},\n",
      "          \"right\": {{\n",
      "            \"table\": \"fxrates\"\n",
      "          }},\n",
      "          \"on_left_key\": \"ohlc_date\",\n",
      "          \"on_right_key\": \"fx_date\",\n",
      "          \"keep_left\": false,\n",
      "          \"keep_right\": false\n",
      "        }},\n",
      "        \"on_left_key\": \"yield_date\",\n",
      "        \"on_right_key\": \"ohlc_date\",\n",
      "        \"keep_left\": true,\n",
      "        \"keep_right\": false\n",
      "      }}\n",
      "    }}\n",
      "    ```\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "### one shot \n",
    "\n",
    "template = ''' \n",
    "    ```\n",
    "    json\n",
    "    {{\n",
    "        \"join_node\": {{\n",
    "        \"join_type\": \"inner\",\n",
    "        \"left\": {{\n",
    "            \"join_type\": \"inner\",\n",
    "            \"left\": {{\n",
    "            \"table\": \"{{tbl_A}}\"\n",
    "            }},\n",
    "            \"right\": {{\n",
    "            \"table\": \"{{tbl_B}}\"\n",
    "            }},\n",
    "            \"on_left_key\": \"{{left_col_to_join_on}}\",\n",
    "            \"on_right_key\": \"{{right_col_to_join_on}}\",\n",
    "            \"keep_left\": true,\n",
    "            \"keep_right\": false\n",
    "        }},\n",
    "        \"right\": {{\n",
    "            \"table\": \"{{tbl_C}}\"\n",
    "        }},\n",
    "        \"on_left_key\": \"{{left_join_col}}\",\n",
    "        \"on_right_key\": \"{{right_join_col}}\",\n",
    "        \"keep_left\": true,\n",
    "        \"keep_right\": true\n",
    "        }}\n",
    "    }}\n",
    "    ```\n",
    "    '''\n",
    "\n",
    "examples = [{\n",
    "    \"user_query\" : \"For the day with the lowest ratio of 5y tsy yield to 10y tsy yield among days where USD to GBP was greater than 0.75, calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price in the ohlc table.\",\n",
    "    \"tables_json\" : ''' \n",
    "    ```json\n",
    "        {{\n",
    "        \"tables\": [\n",
    "          {{\n",
    "            \"name\": \"treasury_yields\",\n",
    "            \"columns\": [\n",
    "              {{\n",
    "                \"original_name\": \"date\",\n",
    "                \"alias\": \"yield_date\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"yield_5_year\",\n",
    "                \"alias\": \"yield_5y_tsy\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"yield_10_year\",\n",
    "                \"alias\": \"yield_10y_tsy\"\n",
    "              }}\n",
    "            ]\n",
    "          }},\n",
    "          {{\n",
    "            \"name\": \"fxrates\",\n",
    "            \"columns\": [\n",
    "              {{\n",
    "                \"original_name\": \"date\",\n",
    "                \"alias\": \"fx_date\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"usd_to_gbp\",\n",
    "                \"alias\": \"usd_gbp\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"usd_to_eur\",\n",
    "                \"alias\": \"usd_eur\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"usd_to_jpy\",\n",
    "                \"alias\": \"usd_jpy\"\n",
    "              }}\n",
    "            ]\n",
    "          }},\n",
    "          {{\n",
    "            \"name\": \"ohlc\",\n",
    "            \"columns\": [\n",
    "              {{\n",
    "                \"original_name\": \"date\",\n",
    "                \"alias\": \"ohlc_date\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"open\",\n",
    "                \"alias\": \"stock_open\"\n",
    "              }},\n",
    "              {{\n",
    "                \"original_name\": \"close\",\n",
    "                \"alias\": \"stock_close\"\n",
    "              }}\n",
    "            ]\n",
    "          }}\n",
    "        ]\n",
    "      }}\n",
    "    ''',\n",
    "    \"output\" : '''\n",
    "    ```json\n",
    "      {{\n",
    "      \"join_node\": {{\n",
    "        \"join_type\": \"inner\",\n",
    "        \"left\": {{\n",
    "          \"table\": \"treasury_yields\"\n",
    "        }},\n",
    "        \"right\": {{\n",
    "          \"join_type\": \"inner\",\n",
    "          \"left\": {{\n",
    "            \"table\": \"ohlc\"\n",
    "          }},\n",
    "          \"right\": {{\n",
    "            \"table\": \"fxrates\"\n",
    "          }},\n",
    "          \"on_left_key\": \"ohlc_date\",\n",
    "          \"on_right_key\": \"fx_date\",\n",
    "          \"keep_left\": false,\n",
    "          \"keep_right\": false\n",
    "        }},\n",
    "        \"on_left_key\": \"yield_date\",\n",
    "        \"on_right_key\": \"ohlc_date\",\n",
    "        \"keep_left\": true,\n",
    "        \"keep_right\": false\n",
    "      }}\n",
    "    }}\n",
    "    ```\n",
    "    '''\n",
    "    }]\n",
    "\n",
    "for example in examples:\n",
    "    print(example['user_query'])\n",
    "    print(f'=' * 30)\n",
    "    print(example['tables_json'])\n",
    "    print(f'=' * 30)\n",
    "    print(example['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joins_json_str(user_query, tables_json, config=config, error_msg=None):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('human', 'Given user query: {user_query} and tables json: {tables_json}'), ('ai', '{output}')]\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "    )\n",
    "    schema_context = get_schema_context(config)\n",
    "    system_message  = f'''Given a user query, a json of table info, return ONLY a valid JSON describing the \n",
    "    joins on the tables required to get the data necessary to answer the user query. The JSON should\n",
    "    be parsable and adhere to proper JSON syntax.\n",
    "    Answer ONLY with a JSON in this format: {template}\n",
    "    Instructions:\n",
    "        - Note the hierarchichal structure, this is to distinguish inner(A, outer(B,C)) != outer(B, inner(A,C))\n",
    "        - For keep_left, keep_right, only keep a column if absolutely necessary, for example some inner\n",
    "        joins you won't need both resulting columns\n",
    "        - don't name any cols the same things\n",
    "        - Make sure the on_right_key, on_left_key are the OLD names (date, not date_ohlc)\n",
    "    '''\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', f'{system_message}'),\n",
    "            few_shot_prompt,\n",
    "            ('human', 'Given user query: {user_query} and tables json: {tables_json}'),\n",
    "        ]\n",
    "    )\n",
    "    chain = final_prompt | config.llm \n",
    "    llm_response = chain.invoke({'user_query' : user_query, \"tables_json\" : tables_json}).content \n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = f'''For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''\n",
    "llm_response = get_joins_json_str(user_query, tables_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join_node': {'join_type': 'inner', 'left': {'join_type': 'inner', 'left': {'table': 'fxrates'}, 'right': {'table': 'ohlc'}, 'on_left_key': 'date', 'on_right_key': 'date', 'keep_left': True, 'keep_right': True}, 'right': {'table': 'treasury_yields'}, 'on_left_key': 'fx_date', 'on_right_key': 'date', 'keep_left': False, 'keep_right': True}}\n"
     ]
    }
   ],
   "source": [
    "joins_json = json.loads(extract_query(llm_response, type='json'))\n",
    "print(joins_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "        \n",
      "    FROM\n",
      "        ((fxrates INNER JOIN ohlc ON fxrates.date = ohlc.date) INNER JOIN treasury_yields ON (fxrates INNER JOIN ohlc ON fxrates.date = ohlc.date).fx_date = treasury_yields.date)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compile(tables_json, joins_json):\n",
    "    def get_columns(table_name):\n",
    "        \"\"\"Get column aliases for the specified table.\"\"\"\n",
    "        for table in tables_json['tables']:\n",
    "            if table['name'] == table_name:\n",
    "                return {col['original_name']: col['alias'] for col in table['columns']}\n",
    "        return {}\n",
    "\n",
    "    def build_select_clause(table_name, keep_columns):\n",
    "        \"\"\"Build the SELECT clause for a given table.\"\"\"\n",
    "        columns = get_columns(table_name)\n",
    "        return [f\"{table_name}.{orig_col} AS {alias}\" for orig_col, alias in columns.items() if alias in keep_columns]\n",
    "\n",
    "    def traverse_joins(join_node, keep_columns):\n",
    "        \"\"\"Recursively traverse join nodes to build SQL JOINs.\"\"\"\n",
    "        if 'table' in join_node:\n",
    "            table_name = join_node['table']\n",
    "            keep_left = join_node.get('keep_left', False)\n",
    "            keep_right = join_node.get('keep_right', False)\n",
    "            if keep_left or keep_right:\n",
    "                keep_columns.update(get_columns(table_name).values())\n",
    "            return table_name, keep_columns\n",
    "\n",
    "        join_type = join_node['join_type'].upper()\n",
    "        left_table, left_keep_columns = traverse_joins(join_node['left'], set())\n",
    "        right_table, right_keep_columns = traverse_joins(join_node['right'], set())\n",
    "\n",
    "        on_left_key = join_node['on_left_key']\n",
    "        on_right_key = join_node['on_right_key']\n",
    "        keep_left = join_node.get('keep_left', False)\n",
    "        keep_right = join_node.get('keep_right', False)\n",
    "\n",
    "        if keep_left:\n",
    "            keep_columns.update(left_keep_columns)\n",
    "        if keep_right:\n",
    "            keep_columns.update(right_keep_columns)\n",
    "\n",
    "        join_clause = (\n",
    "            f\"{left_table} {join_type} JOIN {right_table} \"\n",
    "            f\"ON {left_table}.{on_left_key} = {right_table}.{on_right_key}\"\n",
    "        )\n",
    "\n",
    "        return f\"({join_clause})\", keep_columns\n",
    "\n",
    "    # Start with the top-level join node\n",
    "    final_table, final_keep_columns = traverse_joins(joins_json['join_node'], set())\n",
    "\n",
    "    # Build the SELECT clause\n",
    "    select_clauses = []\n",
    "    for table in tables_json['tables']:\n",
    "        table_columns = get_columns(table['name'])\n",
    "        keep_columns = {col for col in final_keep_columns if col in table_columns.values()}\n",
    "        select_clauses.extend(build_select_clause(table['name'], keep_columns))\n",
    "\n",
    "    select_clause = ',\\n    '.join(select_clauses)\n",
    "\n",
    "    # Assemble the full SQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        {select_clause}\n",
    "    FROM\n",
    "        {final_table}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return query\n",
    "\n",
    "print(compile(tables_json, joins_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tables': [{'name': 'fxrates',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'fx_date'},\n",
       "    {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur'},\n",
       "    {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp'},\n",
       "    {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy'}]},\n",
       "  {'name': 'ohlc',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'ohlc_date'},\n",
       "    {'original_name': 'open', 'alias': 'open_usd'},\n",
       "    {'original_name': 'high', 'alias': 'high_usd'},\n",
       "    {'original_name': 'close', 'alias': 'close_usd'}]},\n",
       "  {'name': 'treasury_yields',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'ty_date'},\n",
       "    {'original_name': 'yield_5_year', 'alias': 'yield_5_year'},\n",
       "    {'original_name': 'yield_7_year', 'alias': 'yield_7_year'},\n",
       "    {'original_name': 'yield_10_year', 'alias': 'yield_10_year'}]}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins_json['join_node']['on_right_key'] = 'ty_date' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins_json['join_node']['left']['on_left_key'] = 'fx_date' \n",
    "joins_json['join_node']['left']['on_right_key'] = 'ohlc_date' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'join_node': {'join_type': 'inner',\n",
       "  'left': {'join_type': 'inner',\n",
       "   'left': {'table': 'fxrates'},\n",
       "   'right': {'table': 'ohlc'},\n",
       "   'on_left_key': 'fx_date',\n",
       "   'on_right_key': 'ohlc_date',\n",
       "   'keep_left': True,\n",
       "   'keep_right': True},\n",
       "  'right': {'table': 'treasury_yields'},\n",
       "  'on_left_key': 'fx_date',\n",
       "  'on_right_key': 'ty_date',\n",
       "  'keep_left': False,\n",
       "  'keep_right': True}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joins_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_usd</th>\n",
       "      <th>high_usd</th>\n",
       "      <th>ohlc_date</th>\n",
       "      <th>open_usd</th>\n",
       "      <th>ty_date</th>\n",
       "      <th>usd_to_eur</th>\n",
       "      <th>usd_to_gbp</th>\n",
       "      <th>usd_to_jpy</th>\n",
       "      <th>yield_10_year</th>\n",
       "      <th>yield_5_year</th>\n",
       "      <th>yield_7_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.244252</td>\n",
       "      <td>122.243837</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>97.847047</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.955216</td>\n",
       "      <td>0.744213</td>\n",
       "      <td>178.670871</td>\n",
       "      <td>2.420872</td>\n",
       "      <td>1.545694</td>\n",
       "      <td>3.533141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.321208</td>\n",
       "      <td>123.517684</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>92.102546</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>0.953731</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>149.179569</td>\n",
       "      <td>2.566896</td>\n",
       "      <td>2.245038</td>\n",
       "      <td>2.461981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.266867</td>\n",
       "      <td>128.192394</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>106.361000</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>0.988302</td>\n",
       "      <td>0.885252</td>\n",
       "      <td>145.902530</td>\n",
       "      <td>3.327936</td>\n",
       "      <td>1.397994</td>\n",
       "      <td>4.226303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.121746</td>\n",
       "      <td>125.600137</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>80.813697</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>0.898221</td>\n",
       "      <td>0.776084</td>\n",
       "      <td>127.671146</td>\n",
       "      <td>4.022134</td>\n",
       "      <td>2.529819</td>\n",
       "      <td>1.773818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.741645</td>\n",
       "      <td>125.857878</td>\n",
       "      <td>2020-01-07 00:00:00</td>\n",
       "      <td>110.707861</td>\n",
       "      <td>2020-01-07 00:00:00</td>\n",
       "      <td>0.890543</td>\n",
       "      <td>0.760646</td>\n",
       "      <td>134.947739</td>\n",
       "      <td>3.628586</td>\n",
       "      <td>1.763754</td>\n",
       "      <td>3.660253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    close_usd    high_usd            ohlc_date    open_usd  \\\n",
       "0   92.244252  122.243837  2020-01-01 00:00:00   97.847047   \n",
       "1   95.321208  123.517684  2020-01-02 00:00:00   92.102546   \n",
       "2   86.266867  128.192394  2020-01-03 00:00:00  106.361000   \n",
       "3  109.121746  125.600137  2020-01-06 00:00:00   80.813697   \n",
       "4  116.741645  125.857878  2020-01-07 00:00:00  110.707861   \n",
       "\n",
       "               ty_date  usd_to_eur  usd_to_gbp  usd_to_jpy  yield_10_year  \\\n",
       "0  2020-01-01 00:00:00    0.955216    0.744213  178.670871       2.420872   \n",
       "1  2020-01-02 00:00:00    0.953731    0.778589  149.179569       2.566896   \n",
       "2  2020-01-03 00:00:00    0.988302    0.885252  145.902530       3.327936   \n",
       "3  2020-01-06 00:00:00    0.898221    0.776084  127.671146       4.022134   \n",
       "4  2020-01-07 00:00:00    0.890543    0.760646  134.947739       3.628586   \n",
       "\n",
       "   yield_5_year  yield_7_year  \n",
       "0      1.545694      3.533141  \n",
       "1      2.245038      2.461981  \n",
       "2      1.397994      4.226303  \n",
       "3      2.529819      1.773818  \n",
       "4      1.763754      3.660253  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def compile(tables_json, joins_json):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      tables_json: {\n",
    "        \"tables\": [\n",
    "          {\n",
    "            \"name\": <table_name>,\n",
    "            \"columns\": [\n",
    "              { \"original_name\": <col>, \"alias\": <col_alias> },\n",
    "              ...\n",
    "            ]\n",
    "          },\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "      joins_json: {\n",
    "        \"join_node\": {\n",
    "          \"join_type\": <\"inner\"|\"left\"|\"right\"|\"full\" etc>,\n",
    "          \"left\": <TABLE or JOIN_NODE>,\n",
    "          \"right\": <TABLE or JOIN_NODE>,\n",
    "          \"on_left_key\": <alias-of-left-col>,\n",
    "          \"on_right_key\": <alias-of-right-col>,\n",
    "          \"keep_left\": <bool>,\n",
    "          \"keep_right\": <bool>\n",
    "        }\n",
    "      }\n",
    "\n",
    "    Returns a string containing the SQL query that joins all tables\n",
    "    and exposes columns/aliases according to 'keep_left'/'keep_right'\n",
    "    and the tables' columns definitions.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Parse the tables_json into a dictionary for quick lookup:\n",
    "    #    { table_name -> { original_col -> alias_col, ... } }\n",
    "    table_defs = {}\n",
    "    for tbl in tables_json[\"tables\"]:\n",
    "        name = tbl[\"name\"]\n",
    "        col_map = {}\n",
    "        for c in tbl[\"columns\"]:\n",
    "            orig = c[\"original_name\"]\n",
    "            alias = c[\"alias\"]\n",
    "            col_map[orig] = alias\n",
    "        table_defs[name] = col_map\n",
    "\n",
    "    # A simple generator so sub-selects each get a unique alias\n",
    "    alias_counter = itertools.count(1)\n",
    "\n",
    "    def next_subalias():\n",
    "        return f\"sub_{next(alias_counter)}\"\n",
    "    \n",
    "    # 2) A helper to build a SELECT list given a table's definition\n",
    "    #    or given a subquery's (which we must have computed).\n",
    "    #\n",
    "    #    We return two things:\n",
    "    #       * \"select_expr\"    -> string that can go into SELECT ...\n",
    "    #       * \"available_cols\" -> dict of { alias -> \"subalias.col_name\" }\n",
    "    #         that can be used by an outer query's ON clauses or further SELECT.\n",
    "    #\n",
    "    #    We must handle \"keep_left\"/\"keep_right\" inside the join\n",
    "    #    so that if keep is false, we exclude the join key from the outer SELECT list.\n",
    "    #\n",
    "    #    However, note we STILL need that join key in the sub-select\n",
    "    #    (not aliased into final output) so the outer query can do the ON condition.\n",
    "    #\n",
    "    #    So for each join node, we’ll produce a sub-select of all the columns that:\n",
    "    #       a) appear in that side’s final output, or\n",
    "    #       b) are used as the join key in the next-larger context.\n",
    "    #\n",
    "    #    The top-level caller will decide whether a join key is \"kept\" or not,\n",
    "    #    and pass that to the recursive call.\n",
    "    \n",
    "    def build_from_node(join_node, needed_join_alias=None):\n",
    "        \"\"\"\n",
    "        Recursively build either:\n",
    "          - A simple \"table\" select expression,\n",
    "          - Or a sub-select expression (if there's a nested join_node).\n",
    "\n",
    "        :param join_node: Either { \"table\": \"some_table\" }\n",
    "                          or a {\"join_type\", \"left\", \"right\", ...} structure.\n",
    "        :param needed_join_alias: an alias (string) for the column that the\n",
    "                                  *outer level* needs to join on. (Could be None)\n",
    "\n",
    "        :return: tuple of:\n",
    "            (sub_select_sql,        # e.g. \"table_name\" or \"(SELECT ... ) AS sub_X\"\n",
    "             available_cols_dict)   # { alias -> \"sub_X.alias\" } for use outside\n",
    "        \"\"\"\n",
    "\n",
    "        # If this is just {\"table\": \"some_table\"}, no actual join:\n",
    "        if \"table\" in join_node:\n",
    "            table_name = join_node[\"table\"]\n",
    "            sub_alias = table_name  # or you can rename as you'd like\n",
    "            col_map = table_defs[table_name]\n",
    "\n",
    "            # Build the list of original->alias:\n",
    "            # For a simple table, we just expose all columns by default,\n",
    "            # but the \"outer\" node might still discard the join key. So we\n",
    "            # do the \"select * from table AS sub_alias\" approach but with explicit columns.\n",
    "            select_cols = []\n",
    "            available_cols = {}\n",
    "            for orig_col, alias_col in col_map.items():\n",
    "                # sub_alias.orig_col as alias_col\n",
    "                select_cols.append(f\"  {sub_alias}.{orig_col} AS {alias_col}\")\n",
    "                available_cols[alias_col] = f\"{sub_alias}.{alias_col}\"\n",
    "\n",
    "            select_expr = \",\\n\".join(select_cols)\n",
    "            from_sql = (\n",
    "                f\"(SELECT\\n{select_expr}\\n\"\n",
    "                f\"FROM {table_name} AS {sub_alias}) AS {sub_alias}\"\n",
    "            )\n",
    "            return from_sql, available_cols\n",
    "\n",
    "        # Otherwise, it's a join node with structure:\n",
    "        # {\n",
    "        #   \"join_type\": ...,\n",
    "        #   \"left\": { table or sub-join },\n",
    "        #   \"right\": { table or sub-join },\n",
    "        #   \"on_left_key\": ...,\n",
    "        #   \"on_right_key\": ...,\n",
    "        #   \"keep_left\": bool,\n",
    "        #   \"keep_right\": bool\n",
    "        # }\n",
    "        join_type = join_node[\"join_type\"].upper() + \" JOIN\"\n",
    "        left_node = join_node[\"left\"]\n",
    "        right_node = join_node[\"right\"]\n",
    "        on_left_key_alias = join_node[\"on_left_key\"]   # e.g. \"ohlc_date\"\n",
    "        on_right_key_alias = join_node[\"on_right_key\"] # e.g. \"fx_date\"\n",
    "        keep_left = join_node[\"keep_left\"]\n",
    "        keep_right = join_node[\"keep_right\"]\n",
    "\n",
    "        # We'll recursively build sub-select for left side and right side.\n",
    "        # But each side might need to \"expose\" its join key column so that\n",
    "        # the *outer* ON condition can see it.  We'll rename these columns\n",
    "        # in the sub-select as well (like `_join_key_left`, `_join_key_right`) to avoid collisions.\n",
    "        #\n",
    "        # We do that by telling the child node: \"please give me <col_alias> in your output\n",
    "        # because I'm going to use it in the parent's ON condition\".\n",
    "        #\n",
    "        # Then, after we get the child's sub-select, if keep_left == False (for left side),\n",
    "        # we remove that from the parent's *final* columns. But we needed it to be present\n",
    "        # in that subquery's SELECT so we can do the join.\n",
    "\n",
    "        left_sql, left_cols = build_from_node(left_node, needed_join_alias=on_left_key_alias)\n",
    "        right_sql, right_cols = build_from_node(right_node, needed_join_alias=on_right_key_alias)\n",
    "\n",
    "        # The child subqueries each have \"available_cols\" as { alias -> subX.alias }.\n",
    "        # Now we can form an ON condition:\n",
    "        left_join_col = left_cols[on_left_key_alias]\n",
    "        right_join_col = right_cols[on_right_key_alias]\n",
    "        on_condition = f\"{left_join_col} = {right_join_col}\"\n",
    "\n",
    "        # Now we want to build a sub-select that includes columns from both sides:\n",
    "        # We'll combine all columns from left_cols and right_cols,\n",
    "        # possibly removing the join keys if keep_left/right are false.\n",
    "        combined_select_lines = []\n",
    "        combined_cols = {}\n",
    "\n",
    "        # Include all columns from left side:\n",
    "        for alias_col, fully_qualified in left_cols.items():\n",
    "            # If this alias_col is the left join key and keep_left is False, skip including in final:\n",
    "            if alias_col == on_left_key_alias and not keep_left:\n",
    "                continue\n",
    "            # else keep it\n",
    "            combined_select_lines.append(f\"  {fully_qualified} AS {alias_col}\")\n",
    "            combined_cols[alias_col] = alias_col  # will refer back to sub-alias from outer\n",
    "\n",
    "        # Include all columns from right side:\n",
    "        for alias_col, fully_qualified in right_cols.items():\n",
    "            # If this alias_col is the right join key and keep_right is False, skip:\n",
    "            if alias_col == on_right_key_alias and not keep_right:\n",
    "                continue\n",
    "            # else keep it\n",
    "            combined_select_lines.append(f\"  {fully_qualified} AS {alias_col}\")\n",
    "            combined_cols[alias_col] = alias_col\n",
    "\n",
    "        # We'll create a new sub-select from left_sql JOIN right_sql ON condition\n",
    "        sub_alias = next_subalias()\n",
    "\n",
    "        sub_select_sql = (\n",
    "            f\"(\\n\"\n",
    "            f\"  SELECT\\n\"\n",
    "            f\"{',\\n'.join(combined_select_lines)}\\n\"\n",
    "            f\"  FROM {left_sql}\\n\"\n",
    "            f\"  {join_type} {right_sql}\\n\"\n",
    "            f\"    ON {on_condition}\\n\"\n",
    "            f\") AS {sub_alias}\"\n",
    "        )\n",
    "\n",
    "        # The \"available_cols\" we return need to be in the form\n",
    "        # { alias -> \"sub_alias.alias\" } so that the outer query can reference them\n",
    "        final_available_cols = {\n",
    "            alias_col: f\"{sub_alias}.{alias_col}\" for alias_col in combined_cols\n",
    "        }\n",
    "\n",
    "        return sub_select_sql, final_available_cols\n",
    "\n",
    "    # 3) The top-level of joins_json has the structure: {\"join_node\": {...}}\n",
    "    root_join_node = joins_json[\"join_node\"]\n",
    "    top_sql, top_cols = build_from_node(root_join_node)\n",
    "\n",
    "    # The top-level sub-select is everything.  Now we wrap it in a final SELECT\n",
    "    # so that we produce a \"flat\" list of columns.  The question is:\n",
    "    # do we simply SELECT * from (top_sql)? Or do we want to pick the columns\n",
    "    # in the order in which they appear in the table_defs? Typically, your\n",
    "    # requirement was “pull each of the cols as aliases” in the final, which\n",
    "    # is effectively all aliases in `top_cols`.\n",
    "    #\n",
    "    # Here we’ll just pull them in alphabetical order for consistency, or you\n",
    "    # could preserve the table order. We skip “hidden” join aliases if they\n",
    "    # got pruned out, but we only have those columns that remain in top_cols anyway.\n",
    "\n",
    "    # In many real-world cases, you can just do: SELECT sub_1.* FROM ( ... ) sub_1\n",
    "    # but we’ll be explicit:\n",
    "    final_alias = \"final\"\n",
    "    output_select_lines = []\n",
    "    # Sort columns to have stable ordering (not required, but can be nice):\n",
    "    for alias_col in sorted(top_cols.keys()):\n",
    "        output_select_lines.append(f\"  {top_cols[alias_col]} AS {alias_col}\")\n",
    "\n",
    "    final_query = (\n",
    "        f\"SELECT\\n\"\n",
    "        f\"{',\\n'.join(output_select_lines)}\\n\"\n",
    "        f\"FROM {top_sql}\\n\"\n",
    "    )\n",
    "\n",
    "    return final_query\n",
    "\n",
    "sql_query = compile(tables_json, joins_json)\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.read_sql(sql_query, config.engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_agent(user_query, config):\n",
    "    table_json_str = get_tables_json_str(user_query, config)\n",
    "    tables_json = json.loads(extract_query(llm_response, type='json'))\n",
    "    joins_json_str = get_joins_json_str(user_query, tables_json, config)\n",
    "    joins_json = json.loads(extract_query(llm_response, type='json'))\n",
    "    df = compile(tables_json, joins_json)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
