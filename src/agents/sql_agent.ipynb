{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic SQL Workflow\n",
    "\n",
    "This is looking at a basic workflow from user query to generating the SQL query that will be executed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from helper import get_paths\n",
    "\n",
    "class Config:\n",
    "    \"\"\"SQL agent config\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_model = 'gpt-4-1106-preview',\n",
    "        temperature  = 0 \n",
    "        ):\n",
    "        path_map  = get_paths()\n",
    "        env_fpath = path_map['env']\n",
    "        sql_fpath = path_map['sql']\n",
    "\n",
    "        load_dotenv(env_fpath)\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=openai_model,\n",
    "            temperature=temperature,\n",
    "            api_key=openai_api_key\n",
    "            )\n",
    "        self.db     = SQLDatabase.from_uri(f\"sqlite:///{sql_fpath}\")\n",
    "        self.engine = create_engine(f\"sqlite:///{sql_fpath}\")\n",
    "\n",
    "config = Config(openai_model='gpt-4o-mini-2024-07-18')\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATABASE SCHEMA:\n",
      "Table: fxrates\n",
      "\n",
      "CREATE TABLE fxrates (\n",
      "\tdate TIMESTAMP, \n",
      "\tusd_to_eur REAL, \n",
      "\tusd_to_gbp REAL, \n",
      "\tusd_to_jpy REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from fxrates table:\n",
      "date\tusd_to_eur\tusd_to_gbp\tusd_to_jpy\n",
      "2020-01-01 00:00:00\t0.9552158220469241\t0.7442134597684561\t178.67087145000016\n",
      "2020-01-02 00:00:00\t0.9537308256723278\t0.7785893129739717\t149.17956918593097\n",
      "2020-01-03 00:00:00\t0.9883022675224316\t0.8852523415853203\t145.90253010300282\n",
      "*/\n",
      "\n",
      "Table: ohlc\n",
      "\n",
      "CREATE TABLE ohlc (\n",
      "\tdate TIMESTAMP, \n",
      "\topen REAL, \n",
      "\thigh REAL, \n",
      "\tlow REAL, \n",
      "\tclose REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ohlc table:\n",
      "date\topen\thigh\tlow\tclose\n",
      "2020-01-01 00:00:00\t97.84704724718776\t122.24383711340477\t55.44555344062485\t92.24425183108863\n",
      "2020-01-02 00:00:00\t92.1025462060139\t123.51768361972003\t66.15905516369102\t95.32120830941909\n",
      "2020-01-03 00:00:00\t106.36100005515581\t128.19239423274277\t55.33471311840124\t86.26686713329055\n",
      "*/\n",
      "\n",
      "Table: treasury_yields\n",
      "\n",
      "CREATE TABLE treasury_yields (\n",
      "\tdate TIMESTAMP, \n",
      "\tyield_5_year REAL, \n",
      "\tyield_7_year REAL, \n",
      "\tyield_10_year REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from treasury_yields table:\n",
      "date\tyield_5_year\tyield_7_year\tyield_10_year\n",
      "2020-01-01 00:00:00\t1.5456939689216451\t3.5331408648502958\t2.420871768439542\n",
      "2020-01-02 00:00:00\t2.2450376346705516\t2.461980928007222\t2.566896305964475\n",
      "2020-01-03 00:00:00\t1.3979936885073319\t4.226303400434457\t3.327935993451753\n",
      "*/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def get_schema_context(config=config, tbls_to_exclude=[]):\n",
    "    db = config.db\n",
    "    tables = db.get_usable_table_names()\n",
    "\n",
    "    schema_lines = []\n",
    "    for table in tables:\n",
    "        if table not in tbls_to_exclude:\n",
    "            table_info = db.get_table_info([table])\n",
    "            schema_lines.append(f\"Table: {table}\\n{table_info}\\n\")\n",
    "\n",
    "    schema_context = (\"DATABASE SCHEMA:\\n\" + \"\\n\".join(schema_lines))\n",
    "    return schema_context, schema_lines\n",
    "\n",
    "def extract_query(response, type='sql'):\n",
    "    pattern = rf\"```{type}\\s+([\\s\\S]*?)\\s+```\"\n",
    "    match   = re.search(pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"Extracting query of type {type} failed: returning response.strip():\\n{response.strip()}\")\n",
    "        return response.strip()\n",
    "\n",
    "if verbose:\n",
    "    print(get_schema_context()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Tables JSON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate the correlation between 7-year treasury yields and stocks' close prices over the last 30 days.\n",
      "==============================\n",
      "\n",
      "```yaml        \n",
      "tables:\n",
      "  - name: \"treasury_yields\"\n",
      "    columns:\n",
      "      - original_name: \"date\"\n",
      "        alias: \"yield_date\"\n",
      "      - original_name: \"yield_7_year\"\n",
      "        alias: \"yield_7y_tsy\"\n",
      "  - name: \"ohlc\"\n",
      "    columns:\n",
      "      - original_name: \"date\"\n",
      "        alias: \"stock_date\"\n",
      "      - original_name: \"close\"\n",
      "        alias: \"stock_close\"\n",
      "```\n",
      "\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "### one shot \n",
    "\n",
    "template = ''' \n",
    "```yaml\n",
    "tables:\n",
    "  - name: \"<db_table_name>\"\n",
    "    columns:\n",
    "      - original_name: \"<col_name_in_db>\"\n",
    "        alias: \"<col_alias_in_output>\"\n",
    "```\n",
    "'''\n",
    "\n",
    "examples = [{\n",
    "    \"input\" : \"Calculate the correlation between 7-year treasury yields and stocks' close prices over the last 30 days.\",\n",
    "    \"output\" : '''\n",
    "```yaml        \n",
    "tables:\n",
    "  - name: \"treasury_yields\"\n",
    "    columns:\n",
    "      - original_name: \"date\"\n",
    "        alias: \"yield_date\"\n",
    "      - original_name: \"yield_7_year\"\n",
    "        alias: \"yield_7y_tsy\"\n",
    "  - name: \"ohlc\"\n",
    "    columns:\n",
    "      - original_name: \"date\"\n",
    "        alias: \"stock_date\"\n",
    "      - original_name: \"close\"\n",
    "        alias: \"stock_close\"\n",
    "```\n",
    "'''\n",
    "}]\n",
    "\n",
    "for example in examples:\n",
    "    print(example['input'])\n",
    "    print(f'=' * 30)\n",
    "    print(example['output'])\n",
    "    print(f'=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from langchain_core.prompts import (\n",
    "    FewShotChatMessagePromptTemplate,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "\n",
    "def get_tables_json_str(user_query, config=config, error_msg=None):\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('human', '{input}'), ('ai', '{output}')]\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "    )\n",
    "    schema_context = get_schema_context(config)\n",
    "    system_message  = f'''Given a user query and a SQLite database schema, return ONLY a valid YAML describing the data required to answer the user query.\n",
    "    Instructions:\n",
    "        Return ONLY the YAML response. Do not include any explanations, comments, or extraneous text.\n",
    "        Ensure all necessary tables and columns required to answer the query are included in the YAML.\n",
    "        If date filtering is required (e.g., \"last 30 days\"), ensure that the YAML specifies the necessary columns but does not include the filtering logic itself.\n",
    "        If engineered features or computations are required, ensure that the YAML speicifies the necessary columns but does not try to perform any computations\n",
    "        Ensure proper YAML syntax, with correct indentation and structure, and verify that the YAML is parsable.\n",
    "        Column names should be clear for what the column contains, as if an independent SQL master would know how to take this info and generate the correct SQL query\n",
    "        For columns, do not name based on how the column will be used, but what the data actually is (if stock_close will be used as a weight still name stock_close, not weight)\n",
    "        Don't name any cols the same things\n",
    "        \n",
    "    Template Format: {template}\n",
    "\n",
    "    Database Schema: {schema_context}'''\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', f'{system_message}'),\n",
    "            few_shot_prompt,\n",
    "            ('human', '{input}'),\n",
    "        ]\n",
    "    )\n",
    "    chain = final_prompt | config.llm \n",
    "    llm_response = chain.invoke({'input' : user_query}).content \n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = f'''For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''\n",
    "llm_response = get_tables_json_str(user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yaml\n",
      "tables:\n",
      "  - name: \"fxrates\"\n",
      "    columns:\n",
      "      - original_name: \"date\"\n",
      "        alias: \"fx_date\"\n",
      "      - original_name: \"usd_to_eur\"\n",
      "        alias: \"usd_to_eur_rate\"\n",
      "      - original_name: \"usd_to_gbp\"\n",
      "        alias: \"usd_to_gbp_rate\"\n",
      "      - original_name: \"usd_to_jpy\"\n",
      "        alias: \"usd_to_jpy_rate\"\n",
      "  - name: \"ohlc\"\n",
      "    columns:\n",
      "      - original_name: \"date\"\n",
      "        alias: \"ohlc_date\"\n",
      "      - original_name: \"open\"\n",
      "        alias: \"stock_open\"\n",
      "      - original_name: \"close\"\n",
      "        alias: \"stock_close\"\n",
      "      - original_name: \"high\"\n",
      "        alias: \"stock_high\"\n",
      "  - name: \"treasury_yields\"\n",
      "    columns:\n",
      "      - original_name: \"date\"\n",
      "        alias: \"yield_date\"\n",
      "      - original_name: \"yield_5_year\"\n",
      "        alias: \"yield_5y_tsy\"\n",
      "      - original_name: \"yield_7_year\"\n",
      "        alias: \"yield_7y_tsy\"\n",
      "      - original_name: \"yield_10_year\"\n",
      "        alias: \"yield_10y_tsy\"\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tables': [{'name': 'fxrates',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'fx_date'},\n",
       "    {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur_rate'},\n",
       "    {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp_rate'},\n",
       "    {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy_rate'}]},\n",
       "  {'name': 'ohlc',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'ohlc_date'},\n",
       "    {'original_name': 'open', 'alias': 'stock_open'},\n",
       "    {'original_name': 'close', 'alias': 'stock_close'},\n",
       "    {'original_name': 'high', 'alias': 'stock_high'}]},\n",
       "  {'name': 'treasury_yields',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'yield_date'},\n",
       "    {'original_name': 'yield_5_year', 'alias': 'yield_5y_tsy'},\n",
       "    {'original_name': 'yield_7_year', 'alias': 'yield_7y_tsy'},\n",
       "    {'original_name': 'yield_10_year', 'alias': 'yield_10y_tsy'}]}]}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_json = yaml.safe_load(extract_query(llm_response, type='yaml'))\n",
    "tables_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joins logic:\n",
    "\n",
    "If there are n tables, we require n-1 joins. To do this we'll give the LLM the above and tell it to choose two from the list of tables to join, taking the two tables and giving a yaml describing the join. We'll also ask if necessary to keep all of the join columns. For now we'll restrict to joins that are one column from each table. We'll then replace the two tables with the single joined table and repeat with a memoryless LLM, repeating n-1 times to get the n-1 joins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = '''\n",
    "    ```\n",
    "    yaml\n",
    "    join_type: \"inner\"\n",
    "    left:\n",
    "      table: \"{{tbl_A}}\"\n",
    "    right:\n",
    "      table: \"{{tbl_B}}\"\n",
    "    on_left_key: \"{{left_col_to_join_on}}\"\n",
    "    on_right_key: \"{{right_col_to_join_on}}\"\n",
    "    keep_left: true \n",
    "    keep_right: false \n",
    "    joined_name: \"{{new_name}}\"\n",
    "    ```\n",
    "'''\n",
    "\n",
    "examples = [{\n",
    "    \"user_query\": \"For the day with the lowest ratio of 5y tsy yield to 10y tsy yield among days where USD to GBP was greater than 0.75, calculate the percentage difference between the EUR equivalent of the close price and the JPY equivalent of the open price in the ohlc table.\",\n",
    "    \"tables\" : ['treasury_yields', 'fxrates', 'ohlc'],\n",
    "    \"tables_yaml\": '''\n",
    "    ```yaml\n",
    "    tables:\n",
    "      - name: \"treasury_yields\"\n",
    "        columns:\n",
    "          - original_name: \"date\"\n",
    "            alias: \"yield_date\"\n",
    "          - original_name: \"yield_5_year\"\n",
    "            alias: \"yield_5y_tsy\"\n",
    "          - original_name: \"yield_10_year\"\n",
    "            alias: \"yield_10y_tsy\"\n",
    "      - name: \"fxrates\"\n",
    "        columns:\n",
    "          - original_name: \"date\"\n",
    "            alias: \"fx_date\"\n",
    "          - original_name: \"usd_to_gbp\"\n",
    "            alias: \"usd_gbp\"\n",
    "          - original_name: \"usd_to_eur\"\n",
    "            alias: \"usd_eur\"\n",
    "          - original_name: \"usd_to_jpy\"\n",
    "            alias: \"usd_jpy\"\n",
    "      - name: \"ohlc\"\n",
    "        columns:\n",
    "          - original_name: \"date\"\n",
    "            alias: \"stock_date\"\n",
    "          - original_name: \"open\"\n",
    "            alias: \"stock_open\"\n",
    "          - original_name: \"close\"\n",
    "            alias: \"stock_close\"\n",
    "    ```\n",
    "    ''',\n",
    "    \"joins_yaml\": '''\n",
    "    ```yaml\n",
    "      join_type: \"inner\"\n",
    "      left:\n",
    "        table: \"ohlc\"\n",
    "      right:\n",
    "        table: \"fxrates\"\n",
    "      on_left_key: \"date\" # referring to what will become stock_date\n",
    "      on_right_key: \"date\" # referring to what will become fx_date\n",
    "      keep_left: true\n",
    "      keep_right: false # these columns are identical so don't need both\n",
    "      joined_name: \"fx_and_ohlc\" \n",
    "    ```\n",
    "    '''\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joins_json_str(user_query, tables_json, config=config, error_msg=None):\n",
    "    tables_yaml = yaml.dump(tables_json, sort_keys=False)\n",
    "    tables = [table['name'] for table in tables_json['tables']]\n",
    "    example_prompt = ChatPromptTemplate.from_messages(\n",
    "        [('human', \n",
    "        'User query: {user_query}, tables yaml: {tables_yaml}, tables: {tables}'), ('ai', '{joins_yaml}')]\n",
    "    )\n",
    "\n",
    "    few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "    )\n",
    "    system_message  = f'''Given a user query, a yaml of table info, and a list of tables, the ultimate goal\n",
    "    is to join all these tables to create a single table that has all the data necessary to answer the user \n",
    "    query. You have the first choice and will choose ONLY two tables to join, as the rest will be handled later. \n",
    "    Return ONLY a valid YAML describing this first join. The YAML should be parsable and adhere to proper YAMl syntax.\n",
    "    Answer ONLY with a YAML in this format: {template}\n",
    "    Instructions:\n",
    "        - Note the order that you choose the joins matters, as if A,B,C are tables, then inner(A, outer(B,C)) != outer(B,inner(A,C))\n",
    "        - Make sure the on_right_key, on_left_key are the OLD names (date, not ohlc_date)\n",
    "        - Make sure at least keep_left or keep_right is True, but only set them most true if both are absolutely necessary. \n",
    "        - joined_name is the name of the joined column. Make sure it is informative \n",
    "    '''\n",
    "    final_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', f'{system_message}'),\n",
    "            few_shot_prompt,\n",
    "            ('human', 'User query: {user_query}, tables yaml: {tables_yaml}, tables: {tables}'),\n",
    "        ]\n",
    "    )\n",
    "    chain = final_prompt | config.llm \n",
    "    llm_response = chain.invoke({'user_query' : user_query, \"tables\" : tables, \"tables_yaml\" : tables_yaml}).content \n",
    "    return llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_join(tables_json, joins_json):\n",
    "    \"\"\"\n",
    "    (a) Removes the two tables (left, right) from tables_json\n",
    "    (b) Creates a new joined table with name = joined_name,\n",
    "        containing the combined columns/aliases. If keep_left\n",
    "        or keep_right is False, drops the respective join key column.\n",
    "        \n",
    "    Returns the updated tables_json with the newly joined table.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract relevant info from joins_json\n",
    "    left_table_name = joins_json['left']['table']\n",
    "    right_table_name = joins_json['right']['table']\n",
    "    on_left_key = joins_json['on_left_key']\n",
    "    on_right_key = joins_json['on_right_key']\n",
    "    keep_left = joins_json['keep_left']\n",
    "    keep_right = joins_json['keep_right']\n",
    "    joined_name = joins_json['joined_name']\n",
    "    \n",
    "    # Find the left and right tables from tables_json\n",
    "    left_table_index = None\n",
    "    right_table_index = None\n",
    "    \n",
    "    for i, table in enumerate(tables_json['tables']):\n",
    "        if table['name'] == left_table_name:\n",
    "            left_table_index = i\n",
    "        elif table['name'] == right_table_name:\n",
    "            right_table_index = i\n",
    "    \n",
    "    if left_table_index is None or right_table_index is None:\n",
    "        raise ValueError(\"Could not find both tables in tables_json.\")\n",
    "    \n",
    "    # Retrieve the table dicts\n",
    "    left_table = tables_json['tables'][left_table_index]\n",
    "    right_table = tables_json['tables'][right_table_index]\n",
    "    \n",
    "    # Remove them from tables_json (remove the higher index first to not mess up the lower index)\n",
    "    for index in sorted([left_table_index, right_table_index], reverse=True):\n",
    "        del tables_json['tables'][index]\n",
    "    \n",
    "    # Build the column list for the new joined table\n",
    "    joined_columns = []\n",
    "    \n",
    "    # Add columns from the left table (omit on_left_key if keep_left is False)\n",
    "    for col in left_table['columns']:\n",
    "        if col['original_name'] == on_left_key and not keep_left:\n",
    "            continue\n",
    "        joined_columns.append(col)\n",
    "    \n",
    "    # Add columns from the right table (omit on_right_key if keep_right is False)\n",
    "    for col in right_table['columns']:\n",
    "        if col['original_name'] == on_right_key and not keep_right:\n",
    "            continue\n",
    "        joined_columns.append(col)\n",
    "    \n",
    "    # Construct the new joined table\n",
    "    joined_table = {\n",
    "        'name': joined_name,\n",
    "        'columns': joined_columns\n",
    "    }\n",
    "    \n",
    "    # Add the new joined table to tables_json\n",
    "    tables_json['tables'].append(joined_table)\n",
    "    \n",
    "    return tables_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tables = len(tables_json['tables'])\n",
    "joins      = []\n",
    "tables0    = tables_json \n",
    "\n",
    "for _ in range(num_tables - 1):\n",
    "    llm_response = get_joins_json_str(user_query, tables_json)\n",
    "    joins_json = yaml.safe_load(extract_query(llm_response, type='yaml'))\n",
    "    joins.append(joins_json)\n",
    "    tables_json = perform_join(tables_json, joins_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join_type': 'inner', 'left': {'table': 'ohlc'}, 'right': {'table': 'fxrates'}, 'on_left_key': 'date', 'on_right_key': 'date', 'keep_left': True, 'keep_right': False, 'joined_name': 'ohlc_with_fxrates'}\n",
      "==============================\n",
      "{'join_type': 'inner', 'left': {'table': 'treasury_yields'}, 'right': {'table': 'ohlc_with_fxrates'}, 'on_left_key': 'date', 'on_right_key': 'date', 'keep_left': True, 'keep_right': False, 'joined_name': 'yields_and_ohlc_fx'}\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for join in joins:\n",
    "    print(join)\n",
    "    print(f'=' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tables': [{'name': 'yields_and_ohlc_fx',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'yield_date'},\n",
       "    {'original_name': 'yield_5_year', 'alias': 'yield_5y_tsy'},\n",
       "    {'original_name': 'yield_7_year', 'alias': 'yield_7y_tsy'},\n",
       "    {'original_name': 'yield_10_year', 'alias': 'yield_10y_tsy'},\n",
       "    {'original_name': 'open', 'alias': 'stock_open'},\n",
       "    {'original_name': 'close', 'alias': 'stock_close'},\n",
       "    {'original_name': 'high', 'alias': 'stock_high'},\n",
       "    {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur_rate'},\n",
       "    {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp_rate'},\n",
       "    {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy_rate'}]}]}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tables': [{'name': 'yields_and_ohlc_fx',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'yield_date'},\n",
       "    {'original_name': 'yield_5_year', 'alias': 'yield_5y_tsy'},\n",
       "    {'original_name': 'yield_7_year', 'alias': 'yield_7y_tsy'},\n",
       "    {'original_name': 'yield_10_year', 'alias': 'yield_10y_tsy'},\n",
       "    {'original_name': 'open', 'alias': 'stock_open'},\n",
       "    {'original_name': 'close', 'alias': 'stock_close'},\n",
       "    {'original_name': 'high', 'alias': 'stock_high'},\n",
       "    {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur_rate'},\n",
       "    {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp_rate'},\n",
       "    {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy_rate'}]}]}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "\n",
    "compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "        \n",
      "    FROM\n",
      "        ((fxrates INNER JOIN ohlc ON fxrates.date = ohlc.date) INNER JOIN treasury_yields ON (fxrates INNER JOIN ohlc ON fxrates.date = ohlc.date).fx_date = treasury_yields.date)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def compile(tables_json, joins_json):\n",
    "    def get_columns(table_name):\n",
    "        \"\"\"Get column aliases for the specified table.\"\"\"\n",
    "        for table in tables_json['tables']:\n",
    "            if table['name'] == table_name:\n",
    "                return {col['original_name']: col['alias'] for col in table['columns']}\n",
    "        return {}\n",
    "\n",
    "    def build_select_clause(table_name, keep_columns):\n",
    "        \"\"\"Build the SELECT clause for a given table.\"\"\"\n",
    "        columns = get_columns(table_name)\n",
    "        return [f\"{table_name}.{orig_col} AS {alias}\" for orig_col, alias in columns.items() if alias in keep_columns]\n",
    "\n",
    "    def traverse_joins(join_node, keep_columns):\n",
    "        \"\"\"Recursively traverse join nodes to build SQL JOINs.\"\"\"\n",
    "        if 'table' in join_node:\n",
    "            table_name = join_node['table']\n",
    "            keep_left = join_node.get('keep_left', False)\n",
    "            keep_right = join_node.get('keep_right', False)\n",
    "            if keep_left or keep_right:\n",
    "                keep_columns.update(get_columns(table_name).values())\n",
    "            return table_name, keep_columns\n",
    "\n",
    "        join_type = join_node['join_type'].upper()\n",
    "        left_table, left_keep_columns = traverse_joins(join_node['left'], set())\n",
    "        right_table, right_keep_columns = traverse_joins(join_node['right'], set())\n",
    "\n",
    "        on_left_key = join_node['on_left_key']\n",
    "        on_right_key = join_node['on_right_key']\n",
    "        keep_left = join_node.get('keep_left', False)\n",
    "        keep_right = join_node.get('keep_right', False)\n",
    "\n",
    "        if keep_left:\n",
    "            keep_columns.update(left_keep_columns)\n",
    "        if keep_right:\n",
    "            keep_columns.update(right_keep_columns)\n",
    "\n",
    "        join_clause = (\n",
    "            f\"{left_table} {join_type} JOIN {right_table} \"\n",
    "            f\"ON {left_table}.{on_left_key} = {right_table}.{on_right_key}\"\n",
    "        )\n",
    "\n",
    "        return f\"({join_clause})\", keep_columns\n",
    "\n",
    "    # Start with the top-level join node\n",
    "    final_table, final_keep_columns = traverse_joins(joins_json['join_node'], set())\n",
    "\n",
    "    # Build the SELECT clause\n",
    "    select_clauses = []\n",
    "    for table in tables_json['tables']:\n",
    "        table_columns = get_columns(table['name'])\n",
    "        keep_columns = {col for col in final_keep_columns if col in table_columns.values()}\n",
    "        select_clauses.extend(build_select_clause(table['name'], keep_columns))\n",
    "\n",
    "    select_clause = ',\\n    '.join(select_clauses)\n",
    "\n",
    "    # Assemble the full SQL query\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        {select_clause}\n",
    "    FROM\n",
    "        {final_table}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    return query\n",
    "\n",
    "print(compile(tables_json, joins_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tables': [{'name': 'fxrates',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'fx_date'},\n",
       "    {'original_name': 'usd_to_eur', 'alias': 'usd_to_eur'},\n",
       "    {'original_name': 'usd_to_gbp', 'alias': 'usd_to_gbp'},\n",
       "    {'original_name': 'usd_to_jpy', 'alias': 'usd_to_jpy'}]},\n",
       "  {'name': 'ohlc',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'ohlc_date'},\n",
       "    {'original_name': 'open', 'alias': 'open_usd'},\n",
       "    {'original_name': 'high', 'alias': 'high_usd'},\n",
       "    {'original_name': 'close', 'alias': 'close_usd'}]},\n",
       "  {'name': 'treasury_yields',\n",
       "   'columns': [{'original_name': 'date', 'alias': 'ty_date'},\n",
       "    {'original_name': 'yield_5_year', 'alias': 'yield_5_year'},\n",
       "    {'original_name': 'yield_7_year', 'alias': 'yield_7_year'},\n",
       "    {'original_name': 'yield_10_year', 'alias': 'yield_10_year'}]}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins_json['join_node']['on_right_key'] = 'ty_date' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins_json['join_node']['left']['on_left_key'] = 'fx_date' \n",
    "joins_json['join_node']['left']['on_right_key'] = 'ohlc_date' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'join_node': {'join_type': 'inner',\n",
       "  'left': {'join_type': 'inner',\n",
       "   'left': {'table': 'fxrates'},\n",
       "   'right': {'table': 'ohlc'},\n",
       "   'on_left_key': 'fx_date',\n",
       "   'on_right_key': 'ohlc_date',\n",
       "   'keep_left': True,\n",
       "   'keep_right': True},\n",
       "  'right': {'table': 'treasury_yields'},\n",
       "  'on_left_key': 'fx_date',\n",
       "  'on_right_key': 'ty_date',\n",
       "  'keep_left': False,\n",
       "  'keep_right': True}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joins_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close_usd</th>\n",
       "      <th>high_usd</th>\n",
       "      <th>ohlc_date</th>\n",
       "      <th>open_usd</th>\n",
       "      <th>ty_date</th>\n",
       "      <th>usd_to_eur</th>\n",
       "      <th>usd_to_gbp</th>\n",
       "      <th>usd_to_jpy</th>\n",
       "      <th>yield_10_year</th>\n",
       "      <th>yield_5_year</th>\n",
       "      <th>yield_7_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92.244252</td>\n",
       "      <td>122.243837</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>97.847047</td>\n",
       "      <td>2020-01-01 00:00:00</td>\n",
       "      <td>0.955216</td>\n",
       "      <td>0.744213</td>\n",
       "      <td>178.670871</td>\n",
       "      <td>2.420872</td>\n",
       "      <td>1.545694</td>\n",
       "      <td>3.533141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.321208</td>\n",
       "      <td>123.517684</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>92.102546</td>\n",
       "      <td>2020-01-02 00:00:00</td>\n",
       "      <td>0.953731</td>\n",
       "      <td>0.778589</td>\n",
       "      <td>149.179569</td>\n",
       "      <td>2.566896</td>\n",
       "      <td>2.245038</td>\n",
       "      <td>2.461981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.266867</td>\n",
       "      <td>128.192394</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>106.361000</td>\n",
       "      <td>2020-01-03 00:00:00</td>\n",
       "      <td>0.988302</td>\n",
       "      <td>0.885252</td>\n",
       "      <td>145.902530</td>\n",
       "      <td>3.327936</td>\n",
       "      <td>1.397994</td>\n",
       "      <td>4.226303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.121746</td>\n",
       "      <td>125.600137</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>80.813697</td>\n",
       "      <td>2020-01-06 00:00:00</td>\n",
       "      <td>0.898221</td>\n",
       "      <td>0.776084</td>\n",
       "      <td>127.671146</td>\n",
       "      <td>4.022134</td>\n",
       "      <td>2.529819</td>\n",
       "      <td>1.773818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.741645</td>\n",
       "      <td>125.857878</td>\n",
       "      <td>2020-01-07 00:00:00</td>\n",
       "      <td>110.707861</td>\n",
       "      <td>2020-01-07 00:00:00</td>\n",
       "      <td>0.890543</td>\n",
       "      <td>0.760646</td>\n",
       "      <td>134.947739</td>\n",
       "      <td>3.628586</td>\n",
       "      <td>1.763754</td>\n",
       "      <td>3.660253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    close_usd    high_usd            ohlc_date    open_usd  \\\n",
       "0   92.244252  122.243837  2020-01-01 00:00:00   97.847047   \n",
       "1   95.321208  123.517684  2020-01-02 00:00:00   92.102546   \n",
       "2   86.266867  128.192394  2020-01-03 00:00:00  106.361000   \n",
       "3  109.121746  125.600137  2020-01-06 00:00:00   80.813697   \n",
       "4  116.741645  125.857878  2020-01-07 00:00:00  110.707861   \n",
       "\n",
       "               ty_date  usd_to_eur  usd_to_gbp  usd_to_jpy  yield_10_year  \\\n",
       "0  2020-01-01 00:00:00    0.955216    0.744213  178.670871       2.420872   \n",
       "1  2020-01-02 00:00:00    0.953731    0.778589  149.179569       2.566896   \n",
       "2  2020-01-03 00:00:00    0.988302    0.885252  145.902530       3.327936   \n",
       "3  2020-01-06 00:00:00    0.898221    0.776084  127.671146       4.022134   \n",
       "4  2020-01-07 00:00:00    0.890543    0.760646  134.947739       3.628586   \n",
       "\n",
       "   yield_5_year  yield_7_year  \n",
       "0      1.545694      3.533141  \n",
       "1      2.245038      2.461981  \n",
       "2      1.397994      4.226303  \n",
       "3      2.529819      1.773818  \n",
       "4      1.763754      3.660253  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def compile(tables_json, joins_json):\n",
    "    \"\"\"\n",
    "    Given:\n",
    "      tables_json: {\n",
    "        \"tables\": [\n",
    "          {\n",
    "            \"name\": <table_name>,\n",
    "            \"columns\": [\n",
    "              { \"original_name\": <col>, \"alias\": <col_alias> },\n",
    "              ...\n",
    "            ]\n",
    "          },\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "      joins_json: {\n",
    "        \"join_node\": {\n",
    "          \"join_type\": <\"inner\"|\"left\"|\"right\"|\"full\" etc>,\n",
    "          \"left\": <TABLE or JOIN_NODE>,\n",
    "          \"right\": <TABLE or JOIN_NODE>,\n",
    "          \"on_left_key\": <alias-of-left-col>,\n",
    "          \"on_right_key\": <alias-of-right-col>,\n",
    "          \"keep_left\": <bool>,\n",
    "          \"keep_right\": <bool>\n",
    "        }\n",
    "      }\n",
    "\n",
    "    Returns a string containing the SQL query that joins all tables\n",
    "    and exposes columns/aliases according to 'keep_left'/'keep_right'\n",
    "    and the tables' columns definitions.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Parse the tables_json into a dictionary for quick lookup:\n",
    "    #    { table_name -> { original_col -> alias_col, ... } }\n",
    "    table_defs = {}\n",
    "    for tbl in tables_json[\"tables\"]:\n",
    "        name = tbl[\"name\"]\n",
    "        col_map = {}\n",
    "        for c in tbl[\"columns\"]:\n",
    "            orig = c[\"original_name\"]\n",
    "            alias = c[\"alias\"]\n",
    "            col_map[orig] = alias\n",
    "        table_defs[name] = col_map\n",
    "\n",
    "    # A simple generator so sub-selects each get a unique alias\n",
    "    alias_counter = itertools.count(1)\n",
    "\n",
    "    def next_subalias():\n",
    "        return f\"sub_{next(alias_counter)}\"\n",
    "    \n",
    "    # 2) A helper to build a SELECT list given a table's definition\n",
    "    #    or given a subquery's (which we must have computed).\n",
    "    #\n",
    "    #    We return two things:\n",
    "    #       * \"select_expr\"    -> string that can go into SELECT ...\n",
    "    #       * \"available_cols\" -> dict of { alias -> \"subalias.col_name\" }\n",
    "    #         that can be used by an outer query's ON clauses or further SELECT.\n",
    "    #\n",
    "    #    We must handle \"keep_left\"/\"keep_right\" inside the join\n",
    "    #    so that if keep is false, we exclude the join key from the outer SELECT list.\n",
    "    #\n",
    "    #    However, note we STILL need that join key in the sub-select\n",
    "    #    (not aliased into final output) so the outer query can do the ON condition.\n",
    "    #\n",
    "    #    So for each join node, we’ll produce a sub-select of all the columns that:\n",
    "    #       a) appear in that side’s final output, or\n",
    "    #       b) are used as the join key in the next-larger context.\n",
    "    #\n",
    "    #    The top-level caller will decide whether a join key is \"kept\" or not,\n",
    "    #    and pass that to the recursive call.\n",
    "    \n",
    "    def build_from_node(join_node, needed_join_alias=None):\n",
    "        \"\"\"\n",
    "        Recursively build either:\n",
    "          - A simple \"table\" select expression,\n",
    "          - Or a sub-select expression (if there's a nested join_node).\n",
    "\n",
    "        :param join_node: Either { \"table\": \"some_table\" }\n",
    "                          or a {\"join_type\", \"left\", \"right\", ...} structure.\n",
    "        :param needed_join_alias: an alias (string) for the column that the\n",
    "                                  *outer level* needs to join on. (Could be None)\n",
    "\n",
    "        :return: tuple of:\n",
    "            (sub_select_sql,        # e.g. \"table_name\" or \"(SELECT ... ) AS sub_X\"\n",
    "             available_cols_dict)   # { alias -> \"sub_X.alias\" } for use outside\n",
    "        \"\"\"\n",
    "\n",
    "        # If this is just {\"table\": \"some_table\"}, no actual join:\n",
    "        if \"table\" in join_node:\n",
    "            table_name = join_node[\"table\"]\n",
    "            sub_alias = table_name  # or you can rename as you'd like\n",
    "            col_map = table_defs[table_name]\n",
    "\n",
    "            # Build the list of original->alias:\n",
    "            # For a simple table, we just expose all columns by default,\n",
    "            # but the \"outer\" node might still discard the join key. So we\n",
    "            # do the \"select * from table AS sub_alias\" approach but with explicit columns.\n",
    "            select_cols = []\n",
    "            available_cols = {}\n",
    "            for orig_col, alias_col in col_map.items():\n",
    "                # sub_alias.orig_col as alias_col\n",
    "                select_cols.append(f\"  {sub_alias}.{orig_col} AS {alias_col}\")\n",
    "                available_cols[alias_col] = f\"{sub_alias}.{alias_col}\"\n",
    "\n",
    "            select_expr = \",\\n\".join(select_cols)\n",
    "            from_sql = (\n",
    "                f\"(SELECT\\n{select_expr}\\n\"\n",
    "                f\"FROM {table_name} AS {sub_alias}) AS {sub_alias}\"\n",
    "            )\n",
    "            return from_sql, available_cols\n",
    "\n",
    "        # Otherwise, it's a join node with structure:\n",
    "        # {\n",
    "        #   \"join_type\": ...,\n",
    "        #   \"left\": { table or sub-join },\n",
    "        #   \"right\": { table or sub-join },\n",
    "        #   \"on_left_key\": ...,\n",
    "        #   \"on_right_key\": ...,\n",
    "        #   \"keep_left\": bool,\n",
    "        #   \"keep_right\": bool\n",
    "        # }\n",
    "        join_type = join_node[\"join_type\"].upper() + \" JOIN\"\n",
    "        left_node = join_node[\"left\"]\n",
    "        right_node = join_node[\"right\"]\n",
    "        on_left_key_alias = join_node[\"on_left_key\"]   # e.g. \"ohlc_date\"\n",
    "        on_right_key_alias = join_node[\"on_right_key\"] # e.g. \"fx_date\"\n",
    "        keep_left = join_node[\"keep_left\"]\n",
    "        keep_right = join_node[\"keep_right\"]\n",
    "\n",
    "        # We'll recursively build sub-select for left side and right side.\n",
    "        # But each side might need to \"expose\" its join key column so that\n",
    "        # the *outer* ON condition can see it.  We'll rename these columns\n",
    "        # in the sub-select as well (like `_join_key_left`, `_join_key_right`) to avoid collisions.\n",
    "        #\n",
    "        # We do that by telling the child node: \"please give me <col_alias> in your output\n",
    "        # because I'm going to use it in the parent's ON condition\".\n",
    "        #\n",
    "        # Then, after we get the child's sub-select, if keep_left == False (for left side),\n",
    "        # we remove that from the parent's *final* columns. But we needed it to be present\n",
    "        # in that subquery's SELECT so we can do the join.\n",
    "\n",
    "        left_sql, left_cols = build_from_node(left_node, needed_join_alias=on_left_key_alias)\n",
    "        right_sql, right_cols = build_from_node(right_node, needed_join_alias=on_right_key_alias)\n",
    "\n",
    "        # The child subqueries each have \"available_cols\" as { alias -> subX.alias }.\n",
    "        # Now we can form an ON condition:\n",
    "        left_join_col = left_cols[on_left_key_alias]\n",
    "        right_join_col = right_cols[on_right_key_alias]\n",
    "        on_condition = f\"{left_join_col} = {right_join_col}\"\n",
    "\n",
    "        # Now we want to build a sub-select that includes columns from both sides:\n",
    "        # We'll combine all columns from left_cols and right_cols,\n",
    "        # possibly removing the join keys if keep_left/right are false.\n",
    "        combined_select_lines = []\n",
    "        combined_cols = {}\n",
    "\n",
    "        # Include all columns from left side:\n",
    "        for alias_col, fully_qualified in left_cols.items():\n",
    "            # If this alias_col is the left join key and keep_left is False, skip including in final:\n",
    "            if alias_col == on_left_key_alias and not keep_left:\n",
    "                continue\n",
    "            # else keep it\n",
    "            combined_select_lines.append(f\"  {fully_qualified} AS {alias_col}\")\n",
    "            combined_cols[alias_col] = alias_col  # will refer back to sub-alias from outer\n",
    "\n",
    "        # Include all columns from right side:\n",
    "        for alias_col, fully_qualified in right_cols.items():\n",
    "            # If this alias_col is the right join key and keep_right is False, skip:\n",
    "            if alias_col == on_right_key_alias and not keep_right:\n",
    "                continue\n",
    "            # else keep it\n",
    "            combined_select_lines.append(f\"  {fully_qualified} AS {alias_col}\")\n",
    "            combined_cols[alias_col] = alias_col\n",
    "\n",
    "        # We'll create a new sub-select from left_sql JOIN right_sql ON condition\n",
    "        sub_alias = next_subalias()\n",
    "\n",
    "        sub_select_sql = (\n",
    "            f\"(\\n\"\n",
    "            f\"  SELECT\\n\"\n",
    "            f\"{',\\n'.join(combined_select_lines)}\\n\"\n",
    "            f\"  FROM {left_sql}\\n\"\n",
    "            f\"  {join_type} {right_sql}\\n\"\n",
    "            f\"    ON {on_condition}\\n\"\n",
    "            f\") AS {sub_alias}\"\n",
    "        )\n",
    "\n",
    "        # The \"available_cols\" we return need to be in the form\n",
    "        # { alias -> \"sub_alias.alias\" } so that the outer query can reference them\n",
    "        final_available_cols = {\n",
    "            alias_col: f\"{sub_alias}.{alias_col}\" for alias_col in combined_cols\n",
    "        }\n",
    "\n",
    "        return sub_select_sql, final_available_cols\n",
    "\n",
    "    # 3) The top-level of joins_json has the structure: {\"join_node\": {...}}\n",
    "    root_join_node = joins_json[\"join_node\"]\n",
    "    top_sql, top_cols = build_from_node(root_join_node)\n",
    "\n",
    "    # The top-level sub-select is everything.  Now we wrap it in a final SELECT\n",
    "    # so that we produce a \"flat\" list of columns.  The question is:\n",
    "    # do we simply SELECT * from (top_sql)? Or do we want to pick the columns\n",
    "    # in the order in which they appear in the table_defs? Typically, your\n",
    "    # requirement was “pull each of the cols as aliases” in the final, which\n",
    "    # is effectively all aliases in `top_cols`.\n",
    "    #\n",
    "    # Here we’ll just pull them in alphabetical order for consistency, or you\n",
    "    # could preserve the table order. We skip “hidden” join aliases if they\n",
    "    # got pruned out, but we only have those columns that remain in top_cols anyway.\n",
    "\n",
    "    # In many real-world cases, you can just do: SELECT sub_1.* FROM ( ... ) sub_1\n",
    "    # but we’ll be explicit:\n",
    "    final_alias = \"final\"\n",
    "    output_select_lines = []\n",
    "    # Sort columns to have stable ordering (not required, but can be nice):\n",
    "    for alias_col in sorted(top_cols.keys()):\n",
    "        output_select_lines.append(f\"  {top_cols[alias_col]} AS {alias_col}\")\n",
    "\n",
    "    final_query = (\n",
    "        f\"SELECT\\n\"\n",
    "        f\"{',\\n'.join(output_select_lines)}\\n\"\n",
    "        f\"FROM {top_sql}\\n\"\n",
    "    )\n",
    "\n",
    "    return final_query\n",
    "\n",
    "sql_query = compile(tables_json, joins_json)\n",
    "\n",
    "import pandas as pd \n",
    "df = pd.read_sql(sql_query, config.engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_agent(user_query, config):\n",
    "    table_json_str = get_tables_json_str(user_query, config)\n",
    "    tables_json = json.loads(extract_query(llm_response, type='json'))\n",
    "    joins_json_str = get_joins_json_str(user_query, tables_json, config)\n",
    "    joins_json = json.loads(extract_query(llm_response, type='json'))\n",
    "    df = compile(tables_json, joins_json)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
