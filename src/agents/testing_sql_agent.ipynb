{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangGraph SQL Agent MVP \n",
    "\n",
    "SQL Agent:\n",
    "- generates tables, generates joins, compiles, then executes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   - sql agent:\n",
    "        - inputs: Config, user query \n",
    "        - outputs: table\n",
    "        - steps: gen_tables -> gen_joins -> compile -> execute \n",
    "        - gen_tables: \n",
    "            - inputs: Config, user query\n",
    "            - outputs: table info\n",
    "                - table info: {table: [(col, alias), ...], ...}\n",
    "            - steps: context -> json_initial -> validate + rewrite -> json\n",
    "            - context: schema, few shot examples, instructions, user query\n",
    "            - validate: \n",
    "                - inputs: user query, json_initial\n",
    "                - outputs: bool (if valid), error msg \n",
    "                - steps: simple validation -> ai validation\n",
    "                - simple validation:\n",
    "                    - steps: check_tables_exist -> check_cols_exist \n",
    "                - ai validation:\n",
    "                    - steps: check_cols_make_sense -> check_names_make_sense\n",
    "            - rewrite:\n",
    "                - add error msg + json_initial + context, put through sql agent\n",
    "                - add fail counter and increment, hard stop at self.num_attempts = 3 tries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent import Config \n",
    "\n",
    "config = Config()\n",
    "llm    = config.llm \n",
    "db     = config.db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv   \n",
    "\n",
    "from typing import Annotated     \n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from agent import Config\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from helper import get_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain_openai\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatOpenAI\n\u001b[0;32m----> 3\u001b[0m llm \u001b[39m=\u001b[39m ChatOpenAI()\n\u001b[1;32m      4\u001b[0m llm\u001b[39m.\u001b[39minvoke(\u001b[39m\"\u001b[39m\u001b[39mHello, world!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text2sql/lib/python3.13/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text2sql/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:578\u001b[0m, in \u001b[0;36mBaseChatOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp_client \u001b[39m=\u001b[39m httpx\u001b[39m.\u001b[39mClient(proxy\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopenai_proxy)\n\u001b[1;32m    577\u001b[0m     sync_specific \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mhttp_client\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp_client}\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_client \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mOpenAI(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mclient_params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msync_specific)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions\n\u001b[1;32m    580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39masync_client:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/text2sql/lib/python3.13/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
