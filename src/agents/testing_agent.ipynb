{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1- Config + Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from dotenv import load_dotenv\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from helper import get_paths\n",
    "\n",
    "class Config:\n",
    "    \"\"\"SQL agent config\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        openai_model = 'gpt-4-1106-preview',\n",
    "        temperature  = 0.7\n",
    "        ):\n",
    "        path_map  = get_paths()\n",
    "        env_fpath = path_map['env']\n",
    "        sql_fpath = path_map['sql']\n",
    "\n",
    "        load_dotenv(env_fpath)\n",
    "        openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        \n",
    "        self.llm = ChatOpenAI(\n",
    "            model=openai_model,\n",
    "            temperature=temperature,\n",
    "            api_key=openai_api_key\n",
    "            )\n",
    "        self.db     = SQLDatabase.from_uri(f\"sqlite:///{sql_fpath}\")\n",
    "        self.engine = create_engine(f\"sqlite:///{sql_fpath}\")\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE fxrates (\n",
      "\tdate TIMESTAMP, \n",
      "\tusd_to_eur REAL, \n",
      "\tusd_to_gbp REAL, \n",
      "\tusd_to_jpy REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from fxrates table:\n",
      "date\tusd_to_eur\tusd_to_gbp\tusd_to_jpy\n",
      "2020-01-01 00:00:00\t0.9552158220469241\t0.7442134597684561\t178.67087145000016\n",
      "2020-01-02 00:00:00\t0.9537308256723278\t0.7785893129739717\t149.17956918593097\n",
      "2020-01-03 00:00:00\t0.9883022675224316\t0.8852523415853203\t145.90253010300282\n",
      "*/\n",
      "\n",
      "CREATE TABLE ohlc (\n",
      "\tdate TIMESTAMP, \n",
      "\topen REAL, \n",
      "\thigh REAL, \n",
      "\tlow REAL, \n",
      "\tclose REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ohlc table:\n",
      "date\topen\thigh\tlow\tclose\n",
      "2020-01-01 00:00:00\t97.84704724718776\t122.24383711340477\t55.44555344062485\t92.24425183108863\n",
      "2020-01-02 00:00:00\t92.1025462060139\t123.51768361972003\t66.15905516369102\t95.32120830941909\n",
      "2020-01-03 00:00:00\t106.36100005515581\t128.19239423274277\t55.33471311840124\t86.26686713329055\n",
      "*/\n",
      "\n",
      "CREATE TABLE treasury_yields (\n",
      "\tdate TIMESTAMP, \n",
      "\tyield_5_year REAL, \n",
      "\tyield_7_year REAL, \n",
      "\tyield_10_year REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from treasury_yields table:\n",
      "date\tyield_5_year\tyield_7_year\tyield_10_year\n",
      "2020-01-01 00:00:00\t1.5456939689216451\t3.5331408648502958\t2.420871768439542\n",
      "2020-01-02 00:00:00\t2.2450376346705516\t2.461980928007222\t2.566896305964475\n",
      "2020-01-03 00:00:00\t1.3979936885073319\t4.226303400434457\t3.327935993451753\n",
      "*/\n",
      "DATABASE SCHEMA:\n",
      "Table: fxrates\n",
      "\n",
      "CREATE TABLE fxrates (\n",
      "\tdate TIMESTAMP, \n",
      "\tusd_to_eur REAL, \n",
      "\tusd_to_gbp REAL, \n",
      "\tusd_to_jpy REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from fxrates table:\n",
      "date\tusd_to_eur\tusd_to_gbp\tusd_to_jpy\n",
      "2020-01-01 00:00:00\t0.9552158220469241\t0.7442134597684561\t178.67087145000016\n",
      "2020-01-02 00:00:00\t0.9537308256723278\t0.7785893129739717\t149.17956918593097\n",
      "2020-01-03 00:00:00\t0.9883022675224316\t0.8852523415853203\t145.90253010300282\n",
      "*/\n",
      "\n",
      "Table: ohlc\n",
      "\n",
      "CREATE TABLE ohlc (\n",
      "\tdate TIMESTAMP, \n",
      "\topen REAL, \n",
      "\thigh REAL, \n",
      "\tlow REAL, \n",
      "\tclose REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from ohlc table:\n",
      "date\topen\thigh\tlow\tclose\n",
      "2020-01-01 00:00:00\t97.84704724718776\t122.24383711340477\t55.44555344062485\t92.24425183108863\n",
      "2020-01-02 00:00:00\t92.1025462060139\t123.51768361972003\t66.15905516369102\t95.32120830941909\n",
      "2020-01-03 00:00:00\t106.36100005515581\t128.19239423274277\t55.33471311840124\t86.26686713329055\n",
      "*/\n",
      "\n",
      "Table: treasury_yields\n",
      "\n",
      "CREATE TABLE treasury_yields (\n",
      "\tdate TIMESTAMP, \n",
      "\tyield_5_year REAL, \n",
      "\tyield_7_year REAL, \n",
      "\tyield_10_year REAL\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from treasury_yields table:\n",
      "date\tyield_5_year\tyield_7_year\tyield_10_year\n",
      "2020-01-01 00:00:00\t1.5456939689216451\t3.5331408648502958\t2.420871768439542\n",
      "2020-01-02 00:00:00\t2.2450376346705516\t2.461980928007222\t2.566896305964475\n",
      "2020-01-03 00:00:00\t1.3979936885073319\t4.226303400434457\t3.327935993451753\n",
      "*/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "\n",
    "def get_schema_context(config=config, tbls_to_exclude=[]):\n",
    "    db = config.db\n",
    "    tables = db.get_usable_table_names()\n",
    "\n",
    "    schema_lines = []\n",
    "    for table in tables:\n",
    "        if table not in tbls_to_exclude:\n",
    "            table_info = db.get_table_info([table])\n",
    "            print(table_info)\n",
    "            schema_lines.append(f\"Table: {table}\\n{table_info}\\n\")\n",
    "\n",
    "    schema_context = (\"DATABASE SCHEMA:\\n\" + \"\\n\".join(schema_lines))\n",
    "    return schema_context\n",
    "\n",
    "def extract_query(response, type='sql'):\n",
    "    pattern = rf\"```{type}\\s+([\\s\\S]*?)\\s+```\"\n",
    "    match   = re.search(pattern, response)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        print(f\"Extracting query of type {type} failed: returning response.strip():\\n{response.strip()}\")\n",
    "        return response.strip()\n",
    "\n",
    "if verbose:\n",
    "    print(get_schema_context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2- User Query to SQL JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "def get_sql_json(prompt, config=config):\n",
    "  \"\"\"\n",
    "  Takes a user query and asks the LLM to produce a JSON specifying which tables/columns to pull.\n",
    "  Validates the JSON structure and join types.\n",
    "  \"\"\"\n",
    "  llm_response = config.llm.invoke(prompt).content \n",
    "  sql_json_str = extract_query(llm_response, type='json')\n",
    "  sql_json = json.loads(sql_json_str)\n",
    "  return sql_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(\n",
    "  intro,\n",
    "  instructions,\n",
    "  json_template, \n",
    "  example_query,\n",
    "  example_response,\n",
    "  user_query\n",
    "  ): \n",
    "  return None \n",
    "\n",
    "        prompt = f'''Given a user query and a SQLite database schema, return ONLY a valid JSON describing the \n",
    "        data required to answer the user query. The JSON should be parsable and adhere to proper JSON syntax.\n",
    "\n",
    "        Instructions:\n",
    "        2. Ensure column names and new column names are strings, and there are no extraneous characters.\n",
    "        3. Be mindful of how many days of data to pull, as certain queries may specify n days but \n",
    "        require more than n to compute the result.\n",
    "        4. Avoid creating new columns or performing calculations; these will be handled in later steps.\n",
    "        5. Ensure new column names are self-explanatory and clear for what they are, not what they will be.\n",
    "        For example do treasury_yield_7_year instead of something like 7y_yield, but don't do\n",
    "        treasury_price_7_year, even if eventually that column will be transformed into price.\n",
    "\n",
    "        Answer ONLY with a JSON in this format:\n",
    "        {{\n",
    "  \"tables\": [\n",
    "    {{\n",
    "      \"name\": \"<db_table_name>\",\n",
    "      \"alias\": \"<alias>\",\n",
    "      \"columns\": [\n",
    "        {{\n",
    "          \"original_name\": \"<col_name_in_db>\",\n",
    "          \"alias\": \"<col_alias_in_output>\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"joins\": [\n",
    "    {{\n",
    "      \"left_table_alias\": \"<alias>\",\n",
    "      \"right_table_alias\": \"<alias>\",\n",
    "      \"left_column\": \"<col_name_in_db>\", \n",
    "      \"right_column\": \"<col_name_in_db>\",\n",
    "      \"join_type\": \"inner\" // or outer, left, right,\n",
    "      \"keep_left\": true // or false to merge then drop left_column,\n",
    "      \"keep_right\": true // or fasle to merge then drop right_coumn\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "        Constraints:\n",
    "        - Join types must be one of: \"inner\", \"left\", \"right\", \"outer\".\n",
    "        - Join keep left/right should only keep absolutely necessary columns- for example\n",
    "        two identical columns shoudn't both be kept\n",
    "        - Join column names must be the OLD name, not the NEW name \n",
    "        - Joins will be applied in order of the json. Note the order does matter here. For example \n",
    "        if the first join is inner(A,B) then next is outer(B, C), what is really happening is \n",
    "        outer(C, inner(A,B)), i.e. not inner(A, outer(B,C))\n",
    "\n",
    "        Database Schema: {schema_context}\n",
    "\n",
    "        Example User Query: Calculate the correlation between 7-year treasury yields and stocks' \n",
    "        close prices over the last 30 days.\n",
    "\n",
    "        Example Labeled Answer:\n",
    "        ```\n",
    "        json\n",
    "        {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"ohlc\",\n",
    "        \"alias\": \"ohlc\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"ohlc_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"close\",\n",
    "            \"alias\": \"stock_close\"\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "        {{\n",
    "        \"name\": \"treasury_yields\",\n",
    "        \"alias\": \"treasury_yields\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"tsy_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_7_year\",\n",
    "            \"alias\": \"tsy_yield_7_year\"\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "    ],\n",
    "    \"joins\": [\n",
    "        {{\n",
    "        \"left_table_alias\": \"ohlc\",\n",
    "        \"right_table_alias\": \"treasury_yields\",\n",
    "        \"left_column\": \"date\",\n",
    "        \"right_column\": \"date\",\n",
    "        \"join_type\": \"inner\",\n",
    "        \"left_keep\": true,\n",
    "        \"right_keep: false\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "    ```\n",
    "        Answer for the following user query: {user_query}\n",
    "        ''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from agent import Agent, Config\n",
    "from helper import get_paths, extract_query, get_schema_context\n",
    "class BasicAgent(Agent):\n",
    "\n",
    "    def __init__(self, config: Config, log_data=True, tbls_to_exclude=[]):\n",
    "        super().__init__(config)\n",
    "        self.schema   = get_schema_context(config, tbls_to_exclude)\n",
    "        self.log_data = log_data\n",
    "        self.path_map = get_paths()  \n",
    "\n",
    "    def _log(self, message: str):\n",
    "        \"\"\"\n",
    "        Helper method to handle logging to both console and a log file.\n",
    "        Appends each message as a new line.\n",
    "        \"\"\"\n",
    "        print(message)\n",
    "        if self.log_data:\n",
    "            try:\n",
    "                with open(self.path_map['log'], 'a') as f:\n",
    "                    f.write(message + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not write to log file: {e}\")\n",
    "\n",
    "    def run(self, user_query: str) -> float:\n",
    "        \"\"\"\n",
    "        Takes a user query string, runs it through:\n",
    "          get_sql_json -> compile_sql -> get_python_prompt -> execute_python\n",
    "        and returns a float result.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 0] Starting 'run' method.\")\n",
    "        self._log(f\"User Query:\\n{user_query}\")\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # 1) Convert the user query to SQL JSON\n",
    "        sql_json = self.get_sql_json(user_query)\n",
    "\n",
    "        # 2) Compile SQL and fetch data into a dataframe\n",
    "        df = self.compile_sql(sql_json)\n",
    "\n",
    "        # 3) Generate a Python prompt describing the next steps\n",
    "        py_prompt = self.get_python_prompt(user_query, df)\n",
    "\n",
    "        # 4) Execute the described Python steps and retrieve the result\n",
    "        result = self.execute_python(py_prompt, df)\n",
    "\n",
    "        end = time.time()\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(f\"[STEP 5] Completed run in {round(end - start, 2)} seconds.\\n\")\n",
    "\n",
    "        # Validate final result is float-like\n",
    "        if not isinstance(result, (int, float)):\n",
    "            raise ValueError(f\"Python Execution Failed: the final result must be a float or int, instead got {type(result)}\")\n",
    "        \n",
    "        return float(result)\n",
    "\n",
    "    def get_sql_json(self, user_query: str) -> dict:\n",
    "        \"\"\"\n",
    "        Takes a user query and asks the LLM to produce a JSON specifying which tables/columns to pull.\n",
    "        Validates the JSON structure and join types.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 1] Generating SQL JSON from user query...\")\n",
    "\n",
    "        schema_context = self.schema\n",
    "        prompt = f'''Given a user query and a SQLite database schema, return ONLY a valid JSON describing the \n",
    "        data required to answer the user query. The JSON should be parsable and adhere to proper JSON syntax.\n",
    "\n",
    "        Instructions:\n",
    "        2. Ensure column names and new column names are strings, and there are no extraneous characters.\n",
    "        3. Be mindful of how many days of data to pull, as certain queries may specify n days but \n",
    "        require more than n to compute the result.\n",
    "        4. Avoid creating new columns or performing calculations; these will be handled in later steps.\n",
    "        5. Ensure new column names are self-explanatory and clear for what they are, not what they will be.\n",
    "        For example do treasury_yield_7_year instead of something like 7y_yield, but don't do\n",
    "        treasury_price_7_year, even if eventually that column will be transformed into price.\n",
    "\n",
    "        Answer ONLY with a JSON in this format:\n",
    "        {{\n",
    "  \"tables\": [\n",
    "    {{\n",
    "      \"name\": \"<db_table_name>\",\n",
    "      \"alias\": \"<alias>\",\n",
    "      \"columns\": [\n",
    "        {{\n",
    "          \"original_name\": \"<col_name_in_db>\",\n",
    "          \"alias\": \"<col_alias_in_output>\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "  ],\n",
    "  \"joins\": [\n",
    "    {{\n",
    "      \"left_table_alias\": \"<alias>\",\n",
    "      \"right_table_alias\": \"<alias>\",\n",
    "      \"left_column\": \"<col_name_in_db>\", \n",
    "      \"right_column\": \"<col_name_in_db>\",\n",
    "      \"join_type\": \"inner\" // or outer, left, right,\n",
    "      \"keep_left\": true // or false to merge then drop left_column,\n",
    "      \"keep_right\": true // or fasle to merge then drop right_coumn\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "        Constraints:\n",
    "        - Join types must be one of: \"inner\", \"left\", \"right\", \"outer\".\n",
    "        - Join keep left/right should only keep absolutely necessary columns- for example\n",
    "        two identical columns shoudn't both be kept\n",
    "        - Join column names must be the OLD name, not the NEW name \n",
    "        - Joins will be applied in order of the json. Note the order does matter here. For example \n",
    "        if the first join is inner(A,B) then next is outer(B, C), what is really happening is \n",
    "        outer(C, inner(A,B)), i.e. not inner(A, outer(B,C))\n",
    "\n",
    "        Database Schema: {schema_context}\n",
    "\n",
    "        Example User Query: Calculate the correlation between 7-year treasury yields and stocks' \n",
    "        close prices over the last 30 days.\n",
    "\n",
    "        Example Labeled Answer:\n",
    "        ```\n",
    "        json\n",
    "        {{\n",
    "    \"tables\": [\n",
    "        {{\n",
    "        \"name\": \"ohlc\",\n",
    "        \"alias\": \"ohlc\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"ohlc_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"close\",\n",
    "            \"alias\": \"stock_close\"\n",
    "            }}\n",
    "        ]\n",
    "        }},\n",
    "        {{\n",
    "        \"name\": \"treasury_yields\",\n",
    "        \"alias\": \"treasury_yields\",\n",
    "        \"columns\": [\n",
    "            {{\n",
    "            \"original_name\": \"date\",\n",
    "            \"alias\": \"tsy_date\"\n",
    "            }},\n",
    "            {{\n",
    "            \"original_name\": \"yield_7_year\",\n",
    "            \"alias\": \"tsy_yield_7_year\"\n",
    "            }}\n",
    "        ]\n",
    "        }}\n",
    "    ],\n",
    "    \"joins\": [\n",
    "        {{\n",
    "        \"left_table_alias\": \"ohlc\",\n",
    "        \"right_table_alias\": \"treasury_yields\",\n",
    "        \"left_column\": \"date\",\n",
    "        \"right_column\": \"date\",\n",
    "        \"join_type\": \"inner\",\n",
    "        \"left_keep\": true,\n",
    "        \"right_keep: false\n",
    "        }}\n",
    "    ]\n",
    "    }}\n",
    "    ```\n",
    "        Answer for the following user query: {user_query}\n",
    "        ''' \n",
    "\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for SQL JSON failed: {e}\")\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"LLM Response (raw):\")\n",
    "        self._log(llm_response)\n",
    "\n",
    "        try:\n",
    "            sql_json_str = extract_query(llm_response, type='json')\n",
    "            sql_json = json.loads(sql_json_str)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"SQL JSON Extraction Failed: {e}\")\n",
    "\n",
    "        return sql_json\n",
    "\n",
    "    \n",
    "    def compile_sql(self, sql_json: dict) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transforms the validated JSON (with optional keep flags in the joins) into a SQL SELECT statement,\n",
    "        executes it, and returns the resulting DataFrame.\n",
    "\n",
    "        The JSON structure must have:\n",
    "        {\n",
    "            \"tables\": [\n",
    "                {\n",
    "                    \"name\": \"ohlc\",\n",
    "                    \"alias\": \"ohlc\",\n",
    "                    \"columns\": [\n",
    "                        {\n",
    "                            \"original_name\": \"date\",\n",
    "                            \"alias\": \"ohlc_date\"\n",
    "                        },\n",
    "                        ...\n",
    "                    ]\n",
    "                },\n",
    "                ...\n",
    "            ],\n",
    "            \"joins\": [\n",
    "                {\n",
    "                    \"left_table_alias\": \"ohlc\",\n",
    "                    \"right_table_alias\": \"treasury_yields\",\n",
    "                    \"left_column\": \"date\",\n",
    "                    \"right_column\": \"date\",\n",
    "                    \"join_type\": \"inner\",\n",
    "                    \"left_keep\": true,\n",
    "                    \"right_keep\": false\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        Returns:\n",
    "            A DataFrame with the queried data.\n",
    "        \"\"\"\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 2] Compiling and running SQL...\")\n",
    "\n",
    "        # 1) Organize the tables in a more flexible structure\n",
    "        #    so we can remove columns if keep flags are false.\n",
    "        table_map = {}  # alias -> { \"name\": <table_name>, \"columns\": [ {original_name, alias}, ... ] }\n",
    "        for tbl in sql_json[\"tables\"]:\n",
    "            table_map[tbl[\"alias\"]] = {\n",
    "                \"name\": tbl[\"name\"],\n",
    "                \"columns\": tbl[\"columns\"][:]  # copy to manipulate\n",
    "            }\n",
    "\n",
    "        # 2) Process each join's keep flags\n",
    "        joins = sql_json.get(\"joins\", [])\n",
    "        for j in joins:\n",
    "            lt_alias = j[\"left_table_alias\"]\n",
    "            rt_alias = j[\"right_table_alias\"]\n",
    "            lt_col   = j[\"left_column\"]\n",
    "            rt_col   = j[\"right_column\"]\n",
    "\n",
    "            # If left_keep = false, remove the left_column from that table's columns\n",
    "            if j.get(\"left_keep\") is False:\n",
    "                # find the column in table_map[lt_alias][\"columns\"] that has original_name == lt_col\n",
    "                filtered_cols = []\n",
    "                for c in table_map[lt_alias][\"columns\"]:\n",
    "                    if c[\"original_name\"] == lt_col:\n",
    "                        # skip it\n",
    "                        continue\n",
    "                    filtered_cols.append(c)\n",
    "                table_map[lt_alias][\"columns\"] = filtered_cols\n",
    "\n",
    "            # If right_keep = false, remove the right_column from that table's columns\n",
    "            if j.get(\"right_keep\") is False:\n",
    "                filtered_cols = []\n",
    "                for c in table_map[rt_alias][\"columns\"]:\n",
    "                    if c[\"original_name\"] == rt_col:\n",
    "                        continue\n",
    "                    filtered_cols.append(c)\n",
    "                table_map[rt_alias][\"columns\"] = filtered_cols\n",
    "\n",
    "        # 3) Build SELECT clause from the (potentially updated) table_map\n",
    "        select_parts = []\n",
    "        for tbl_alias, tbl_info in table_map.items():\n",
    "            for col in tbl_info[\"columns\"]:\n",
    "                original = col[\"original_name\"]\n",
    "                alias = col[\"alias\"]\n",
    "                select_parts.append(f'\"{tbl_alias}\".\"{original}\" AS \"{alias}\"')\n",
    "\n",
    "        if not select_parts:\n",
    "            raise ValueError(\"No columns to select after applying keep flags.\")\n",
    "\n",
    "        select_clause = \",\\n    \".join(select_parts)\n",
    "\n",
    "        # 4) Build FROM + JOIN\n",
    "        #    We still rely on the same join logic, but note we might have removed certain columns.\n",
    "        if len(joins) == 0:\n",
    "            # No joins: just use the first table\n",
    "            all_tables = sql_json[\"tables\"]\n",
    "            if len(all_tables) == 0:\n",
    "                raise ValueError(\"No tables available to compile SQL.\")\n",
    "            first_tbl = all_tables[0]\n",
    "            from_clause = f'\"{first_tbl[\"name\"]}\" \"{first_tbl[\"alias\"]}\"'\n",
    "        else:\n",
    "            # Use the first join's left_table_alias as the base\n",
    "            base_alias = joins[0][\"left_table_alias\"]\n",
    "            base_table_name = table_map[base_alias][\"name\"]\n",
    "            from_clause = f'\"{base_table_name}\" \"{base_alias}\"'\n",
    "\n",
    "            for j in joins:\n",
    "                right_alias = j[\"right_table_alias\"]\n",
    "                right_table_name = table_map[right_alias][\"name\"]\n",
    "                join_type = j[\"join_type\"].upper()\n",
    "                from_clause += (\n",
    "                    f'\\n{join_type} JOIN \"{right_table_name}\" \"{right_alias}\" '\n",
    "                    f'ON \"{j[\"left_table_alias\"]}\".\"{j[\"left_column\"]}\" = '\n",
    "                    f'\"{j[\"right_table_alias\"]}\".\"{j[\"right_column\"]}\"'\n",
    "                )\n",
    "\n",
    "        # 5) Construct final SQL\n",
    "        query = f\"\"\"\n",
    "        SELECT\n",
    "            {select_clause}\n",
    "        FROM {from_clause}\n",
    "        \"\"\".strip()\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"Generated SQL Query:\")\n",
    "        self._log(query)\n",
    "\n",
    "        # 6) Execute the query\n",
    "        try:\n",
    "            df = pd.read_sql(query, self.config.engine)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"SQL Execution Failed: {e}\")\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 2] SQL Query executed. Here's df.head():\")\n",
    "        self._log(df.head().to_string())\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_python_prompt(self, user_query: str, df: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Given the user query and a pandas DataFrame, produce a textual prompt describing\n",
    "        how to perform the Python computations that answer the query.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Generating Python prompt...\")\n",
    "\n",
    "        prompt = f''' \n",
    "        Given a user query and a pandas dataframe with the relevant data, only write \n",
    "        CODE DESCRIPTION: CODE DESCRIPTION, where CODE DESCRIPTION is a prompt \n",
    "        that (a) gives a high level goal, (b) gives a step by step method that describes how \n",
    "        to take the dataframe (called df) and write python code to perform \n",
    "        relevant computations to answer the user query. Don't write any code, but write \n",
    "        the prompt such that if an independent python master with access to df + your instructions could \n",
    "        easily answer the original user query. Be specific about how to perform the computations,\n",
    "        including any relevant math, what functions to use (assume pandas, numpy access). \n",
    "\n",
    "        Example User Query: Calculate the correlation between 7 year treasury yields and stocks close over the last 30 days\n",
    "        in the table.\n",
    "        Example Dataframe (df.head()): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Answer:\n",
    "        CODE DESCRIPTION: \n",
    "        Overall Goal: Calculate correlation between treasury_yield_7_year and stock close over the most recent 30 days.\n",
    "        Step 1: take df with cols treasury_yield_7_year, stock_close, date \n",
    "        Step 2: filter df by sorting by date and taking only the most recent 30 days\n",
    "        Step 3: calculate correlation between treasury_yield_7_year and stock_close using pandas corr function.\n",
    "\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        User Query: {user_query}\n",
    "        '''\n",
    "        try:\n",
    "            py_prompt = self.config.llm.invoke(prompt).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python prompt failed: {e}\")\n",
    "\n",
    "        if not isinstance(py_prompt, str) or not py_prompt.strip():\n",
    "            raise ValueError(\"Python Prompt Generation Failed: Did not receive a valid string from LLM.\")\n",
    "        \n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 3] Completed: Python prompt generated.\")\n",
    "        self._log(\"Generated Python Prompt:\")\n",
    "        self._log(py_prompt)\n",
    "\n",
    "        return py_prompt\n",
    "\n",
    "    def execute_python(self, py_prompt: str, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Generate Python code based on the py_prompt, execute it, and return the 'result' variable.\n",
    "        \"\"\"\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Generating and executing Python code...\")\n",
    "\n",
    "        py_code_request = f''' \n",
    "        Given a pandas dataframe df and a description to perform a specific computation, \n",
    "        generate syntactically correct python code wrapped in python QUERY` that takes \n",
    "        the raw dataframe and performs any computations to fully answer the user's query. \n",
    "        Assume access to NumPy (v{np.__version__}), Pandas (v{pd.__version__}) and that \n",
    "        the dataframe is called df. The output of the code should be the variable that \n",
    "        contains the result of the user's query (call this variable result)\n",
    "\n",
    "        Example Dataframe (df): \n",
    "        Date,Treasury Yield (7-Year),Stock Close\n",
    "        2024-01-01 00:00:00,4.113933,84.676268\n",
    "        2023-12-29 00:00:00,4.117221,100.393128\n",
    "        2023-12-28 00:00:00,2.391113,112.97598\n",
    "        2023-12-27 00:00:00,1.482054,119.224503\n",
    "        2023-12-26 00:00:00,4.187207,108.335695\n",
    "\n",
    "        Example Prompt: Given df with cols treasury_yield_7_year, stock_close, date, use pandas corr function\n",
    "        to compute the correlation between treasury_yield_7_year and stock close. \n",
    "\n",
    "        Example Labeled Answer: \n",
    "        ```\n",
    "        python\n",
    "        ### calculate corr btwn 7yr tsy and stock closes \n",
    "        df     = df.sort_values('date')[:30]\n",
    "        result = df['treasury_yield_7_year'].corr(df['stock_close'])    \n",
    "        ```\n",
    "        df.iloc[:5,:].T: {df.iloc[:5,:].T}\n",
    "        Prompt: {py_prompt}\n",
    "        '''\n",
    "        try:\n",
    "            llm_response = self.config.llm.invoke(py_code_request).content\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"LLM invocation for Python code generation failed: {e}\")\n",
    "\n",
    "        # Extract python code block\n",
    "        try:\n",
    "            code = extract_query(llm_response, type='python')\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Python Code Extraction Failed: {e}\")\n",
    "\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"Generated Python Code:\")\n",
    "        self._log(code)\n",
    "\n",
    "        namespace = {'pd': pd, 'np': np, 'df': df, 'plt': plt}\n",
    "        try:\n",
    "            exec(code, namespace)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Python Execution Failed: error executing python: {e}\")\n",
    "\n",
    "        result = namespace.get('result', None)\n",
    "        self._log(\"=\" * 50)\n",
    "        self._log(\"[STEP 4] Result from executed code:\")\n",
    "        self._log(str(result))\n",
    "\n",
    "        return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    config     = Config()\n",
    "    agent      = BasicAgent(config)\n",
    "    user_queries = ['''For the day with the lowest ratio of 5y tsy yield to 10y tsy yield \n",
    "    among days where USD to GBP was greater than 0.75, calculate the percentage difference \n",
    "    between the EUR equivalent of the close price and the JPY equivalent of the open price \n",
    "    in the ohlc table.''','''On the day where the absolute difference between 7y tsy yield \n",
    "    and 10y tsy yield was maximum, compute the ratio of the USD equivalent of the difference \n",
    "    between high and low prices in the ohlc table to the product of USD:EUR and USD:JPY \n",
    "    for that day.''', '''\"For the day where the sum of usd_to_eur, usd_to_gbp, and usd_to_jpy \n",
    "    was closest to 150, calculate the weighted average of the EUR equivalent of open, the GBP \n",
    "    equivalent of close, and the JPY equivalent of high, with weights being the corresponding \n",
    "    treasury yields'''] \n",
    "\n",
    "    # user_query = '''For s in [1,2], of the days where the stock price \n",
    "    # movement := close - open was more than s std deviations from the mean, look at the distribution \n",
    "    # of 7yr tsy yield - 5yr tsy yield. To visualize this, assume access to matplotlib.pyplot as plt and \n",
    "    # make 2 plots, the left where s = 1 and a histogram of 7yr - 5yr tsy yields with lines at 25 percentile,\n",
    "    # 50th percentile, 75th, and then right same with s=2. Then return the median when s=1. \n",
    "    # '''\n",
    "    for user_query in user_queries[:1]:\n",
    "        result = agent.run(user_query)  \n",
    "        print(\"Final numeric result:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.1 ('text2sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83f3fa5421668a4833642a2b44b5c134ea4eb569c2fa67e79bb11743fa413784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
